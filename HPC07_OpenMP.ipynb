{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "98196e40-fc9a-46ad-8cf7-07fa5b272d7a",
      "metadata": {
        "id": "98196e40-fc9a-46ad-8cf7-07fa5b272d7a"
      },
      "source": [
        "<h1 align=\"center\">Computación de Alto Desempeño</h1>\n",
        "<h1 align=\"center\">OpenMP</h1>\n",
        "<h1 align=\"center\">2024</h1>\n",
        "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed8606e1-8ac9-4f6d-bc49-4455c0a44ce2",
      "metadata": {
        "id": "ed8606e1-8ac9-4f6d-bc49-4455c0a44ce2"
      },
      "source": [
        "***\n",
        "|[![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)](mailto:calvarezh@udemedellin.edu.co)||[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/HPC/HPC07_OpenMP.ipynb)\n",
        "|-:|:-|--:|\n",
        "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|\n",
        "\n",
        "<table>\n",
        " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
        " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
        "</table>\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7976c8d0-1f7f-4cdc-b541-040a1e6b06e1",
      "metadata": {
        "id": "7976c8d0-1f7f-4cdc-b541-040a1e6b06e1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción a OpenMP y MPI"
      ],
      "metadata": {
        "id": "HNWYvYl68ENp"
      },
      "id": "HNWYvYl68ENp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el ámbito de la computación de alto rendimiento (HPC), OpenMP y MPI son dos tecnologías ampliamente utilizadas para paralelizar aplicaciones, permitiendo que los programas aprovechen el poder de múltiples procesadores o núcleos. Cada una de estas herramientas tiene sus propias características, ventajas y limitaciones, y se emplean en diferentes contextos dependiendo de las necesidades del proyecto."
      ],
      "metadata": {
        "id": "Rwz6DbWW8M5Q"
      },
      "id": "Rwz6DbWW8M5Q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OpenMP (Open Multi-Processing)**"
      ],
      "metadata": {
        "id": "kEFhWhld8Qes"
      },
      "id": "kEFhWhld8Qes"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Características Principales:**\n",
        "- **Enfoque en Memoria Compartida:** OpenMP es ideal para sistemas con memoria compartida, donde todos los hilos de ejecución tienen acceso a la misma memoria física. Esto incluye arquitecturas como computadoras multicore o multiprocesadores con un solo espacio de memoria.\n",
        "- **Facilidad de Uso:** OpenMP se integra directamente en lenguajes como C, C++ y Fortran mediante directivas de compilador, lo que permite paralelizar el código de manera incremental y sencilla.\n",
        "- **Modelo de Programación Basado en Hilos:** OpenMP utiliza hilos (threads) para ejecutar tareas en paralelo. El programador puede controlar el número de hilos y cómo se distribuyen las tareas entre ellos.\n",
        "- **Paralelismo Explícito:** El programador indica explícitamente qué partes del código deben ejecutarse en paralelo, lo que da un control fino sobre la optimización.\n",
        "\n",
        "**Cuándo Usar OpenMP:**\n",
        "- En sistemas con arquitecturas de memoria compartida.\n",
        "- Cuando se requiere un paralelismo de grano fino, donde las tareas pueden ser fácilmente divididas en pequeños fragmentos.\n",
        "- En proyectos donde se busca una implementación rápida y sencilla de paralelismo sin necesidad de grandes cambios en la estructura del código.\n",
        "\n",
        "**Ventajas:**\n",
        "- Sencillez y rapidez en la implementación.\n",
        "- Facilita la depuración debido a su integración directa con el código secuencial.\n",
        "- Permite paralelismo dinámico, ajustando el número de hilos en tiempo de ejecución.\n",
        "\n",
        "**Limitaciones:**\n",
        "- No es adecuado para sistemas de memoria distribuida.\n",
        "- La escalabilidad está limitada al número de núcleos disponibles en una sola máquina.\n"
      ],
      "metadata": {
        "id": "q_eMWN468FvA"
      },
      "id": "q_eMWN468FvA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MPI (Message Passing Interface)**\n"
      ],
      "metadata": {
        "id": "46A9LHBu8YVK"
      },
      "id": "46A9LHBu8YVK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Características Principales:**\n",
        "- **Enfoque en Memoria Distribuida:** MPI es ideal para sistemas de memoria distribuida, donde cada nodo del sistema tiene su propia memoria local, como en clústeres de computadoras.\n",
        "- **Flexibilidad y Escalabilidad:** MPI permite que las aplicaciones se escalen a miles de nodos, lo que es esencial en aplicaciones científicas y de ingeniería que requieren un poder de cómputo masivo.\n",
        "- **Modelo de Programación Basado en Mensajes:** MPI utiliza un modelo de paso de mensajes, donde los procesos se comunican entre sí enviando y recibiendo mensajes. Cada proceso tiene su propio espacio de memoria, lo que reduce los problemas de sincronización.\n",
        "- **Compatibilidad y Portabilidad:** MPI es compatible con múltiples plataformas y es el estándar de facto en computación paralela en sistemas de memoria distribuida.\n",
        "\n",
        "**Cuándo Usar MPI:**\n",
        "- En sistemas con arquitecturas de memoria distribuida, como clústeres de computadoras.\n",
        "- En aplicaciones que requieren alta escalabilidad y que necesitan ejecutarse en varios nodos de una red.\n",
        "- Cuando se trabaja con datos que no pueden ser almacenados en la memoria de una sola máquina y deben distribuirse entre varios nodos.\n",
        "\n",
        "**Ventajas:**\n",
        "- Alta escalabilidad y flexibilidad.\n",
        "- Permite aprovechar sistemas heterogéneos, donde cada nodo puede tener diferentes capacidades de hardware.\n",
        "- Reduce los problemas de sincronización gracias a su modelo de memoria distribuida.\n",
        "\n",
        "**Limitaciones:**\n",
        "- Mayor complejidad en la programación y depuración.\n",
        "- Requiere un diseño cuidadoso del algoritmo para minimizar el overhead de comunicación entre nodos.\n",
        "- No es tan eficiente en arquitecturas de memoria compartida debido al overhead de comunicación."
      ],
      "metadata": {
        "id": "VQiM3ZFz8ZF2"
      },
      "id": "VQiM3ZFz8ZF2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenMP"
      ],
      "metadata": {
        "id": "A5PYh6E8-vfH"
      },
      "id": "A5PYh6E8-vfH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenMP es:\n",
        "\n",
        "- **Una Interfaz de Programación de Aplicaciones (API):** Que se utiliza para dirigir explícitamente el paralelismo en memoria compartida utilizando múltiples hilos.\n",
        "- **Compuesta por tres componentes principales:**\n",
        "  - **Directivas del compilador**\n",
        "  - **Rutinas de la biblioteca en tiempo de ejecución**\n",
        "  - **Variables de entorno**\n",
        "- **Una abreviatura para:**\n",
        "  - **Versión corta:** Open Multi-Processing\n",
        "  - **Versión larga:** Especificaciones abiertas para la Multi-Processing mediante el trabajo colaborativo entre partes interesadas de la industria del hardware y software, el gobierno y la academia.\n",
        "\n",
        "### OpenMP no es:\n",
        "\n",
        "- **Implementada necesariamente de manera idéntica por todos los proveedores.**\n",
        "- **Garantizada para hacer el uso más eficiente de la memoria compartida.**\n",
        "- **Obligada a verificar dependencias de datos, conflictos de datos, condiciones de carrera o interbloqueos.**\n",
        "- **Obligada a verificar secuencias de código que causen que un programa se clasifique como no conforme.**\n",
        "- **Diseñada para garantizar que la entrada o salida al mismo archivo sea síncrona cuando se ejecuta en paralelo. El programador es responsable de sincronizar la entrada y salida.**\n",
        "\n",
        "### Objetivos de OpenMP:\n",
        "\n",
        "- **Estandarización:**\n",
        "  - Proporcionar un estándar entre una variedad de arquitecturas/plataformas de memoria compartida.\n",
        "  - Definido y respaldado conjuntamente por un grupo de grandes proveedores de hardware y software.\n",
        "\n",
        "- **Eficiencia y Sencillez:**\n",
        "  - Establecer un conjunto simple y limitado de directivas para programar máquinas de memoria compartida.\n",
        "  - Se puede implementar un paralelismo significativo utilizando solo 3 o 4 directivas.\n",
        "  - Este objetivo se está volviendo menos relevante con cada nueva versión.\n",
        "\n",
        "- **Facilidad de Uso:**\n",
        "  - Proporcionar la capacidad de paralelizar un programa secuencial de manera incremental, a diferencia de las bibliotecas de paso de mensajes que típicamente requieren un enfoque de todo o nada.\n",
        "  - Proporcionar la capacidad de implementar paralelismo tanto de grano grueso como de grano fino.\n",
        "\n",
        "- **Portabilidad:**\n",
        "  - La API está especificada para C/C++ y Fortran.\n",
        "  - Foro público para la API y membresía.\n",
        "  - La mayoría de las principales plataformas han sido implementadas, incluidas plataformas Unix/Linux y Windows."
      ],
      "metadata": {
        "id": "VUVVyEN3ABDe"
      },
      "id": "VUVVyEN3ABDe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de Programación OpenMP"
      ],
      "metadata": {
        "id": "RFfr4jtPBw4i"
      },
      "id": "RFfr4jtPBw4i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenMP se basa en dos modelos principales: el modelo de memoria y el modelo de ejecución.\n",
        "\n",
        "#### **Modelo de Memoria Compartida:**\n",
        "OpenMP está diseñado para máquinas multiprocesador/multinúcleo con memoria compartida. La arquitectura subyacente puede ser de memoria compartida de acceso uniforme (UMA) o de acceso no uniforme (NUMA).\n",
        "\n",
        "#### **Modelo de Ejecución de OpenMP:**\n",
        "\n",
        "**Paralelismo Basado en Hilos:**\n",
        "Los programas de OpenMP logran el paralelismo exclusivamente mediante el uso de hilos. Un hilo de ejecución es la unidad más pequeña de procesamiento que puede ser programada por un sistema operativo. Puedes pensar en un hilo como una subrutina que se puede ejecutar de manera autónoma.\n",
        "\n",
        "- Los hilos existen dentro de los recursos de un solo proceso. Sin el proceso, los hilos dejan de existir.\n",
        "- Típicamente, el número de hilos coincide con el número de procesadores/núcleos de la máquina. Sin embargo, el uso real de los hilos depende de la aplicación.\n",
        "\n",
        "**Paralelismo Explícito:**\n",
        "OpenMP es un modelo de programación explícito (no automático), lo que ofrece al programador un control total sobre la paralelización.\n",
        "\n",
        "- La paralelización puede ser tan simple como tomar un programa secuencial e insertar directivas de compilador.\n",
        "- O tan complejo como insertar subrutinas para establecer múltiples niveles de paralelismo, bloqueos y hasta bloqueos anidados.\n",
        "\n",
        "**Modelo Fork-Join:**\n",
        "OpenMP utiliza el modelo de ejecución paralelo fork-join.\n",
        "\n",
        "- **FORK:** Todos los programas OpenMP comienzan como un solo proceso: el hilo maestro. El hilo maestro ejecuta secuencialmente hasta que se encuentra la primera construcción de región paralela.\n",
        "- **JOIN:** Cuando los hilos del equipo completan las instrucciones en la construcción de la región paralela, se sincronizan y terminan, dejando solo al hilo maestro.\n",
        "\n",
        "El número de regiones paralelas y los hilos que las componen son arbitrarios.\n",
        "\n",
        "**Basado en Directivas de Compilador:**\n",
        "La mayor parte del paralelismo en OpenMP se especifica mediante el uso de directivas de compilador que se incrustan en el código fuente de C/C++ o Fortran.\n",
        "\n",
        "**Paralelismo Anidado:**\n",
        "La API permite colocar regiones paralelas dentro de otras regiones paralelas. Las implementaciones pueden o no admitir esta característica.\n",
        "\n",
        "**Hilos Dinámicos:**\n",
        "La API permite que el entorno de ejecución altere dinámicamente el número de hilos utilizados para ejecutar regiones paralelas, con la intención de promover un uso más eficiente de los recursos, si es posible. Las implementaciones pueden o no soportar esta característica.\n",
        "\n",
        "**Entrada/Salida (I/O):**\n",
        "OpenMP no especifica nada sobre I/O paralelo. Depende completamente del programador garantizar que la entrada y salida se realicen correctamente en el contexto de un programa multi-hilo.\n",
        "\n",
        "#### **Interacción entre el Modelo de Ejecución y el Modelo de Memoria:**\n",
        "\n",
        "- **Single-Program-Multiple-Data (SPMD):** Es el paradigma de programación subyacente: todos los hilos tienen el potencial de ejecutar el mismo código de programa; sin embargo, cada hilo puede acceder y modificar diferentes datos y recorrer diferentes caminos de ejecución.\n",
        "  \n",
        "- **Vista de Memoria Relajada:** OpenMP proporciona una vista \"relajada\" y \"temporal\" de la memoria de los hilos: los hilos tienen acceso igual a la memoria compartida donde las variables pueden ser recuperadas/almacenadas. Cada hilo también tiene sus propias copias temporales de variables que pueden modificarse independientemente de las variables en la memoria.\n",
        "\n",
        "- **Consistencia de Datos:** Cuando es crítico que todos los hilos tengan una vista consistente de una variable compartida, el programador (o el compilador) es responsable de asegurar que la variable sea actualizada por todos los hilos según sea necesario, mediante una acción explícita, como `FLUSH`, o implícitamente (a través del reconocimiento del compilador al salir de regiones paralelas).\n",
        "\n",
        "#### **Programación en OpenMP:**\n",
        "\n",
        "- Método para iniciar hilos paralelos.\n",
        "- Método para descubrir cuántos hilos están ejecutándose.\n",
        "- Necesidad de identificar hilos de manera única.\n",
        "- Método para unir hilos para ejecución secuencial.\n",
        "- Método para sincronizar hilos.\n",
        "- Asegurar una vista consistente de los elementos de datos cuando sea necesario.\n",
        "- Requiere verificar dependencias de datos, conflictos de datos, condiciones de carrera o interbloqueos."
      ],
      "metadata": {
        "id": "-tFOwNBXBw7S"
      },
      "id": "-tFOwNBXBw7S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descripción General de la API OpenMP"
      ],
      "metadata": {
        "id": "3VQHpAmLC0ts"
      },
      "id": "3VQHpAmLC0ts"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tres Componentes:\n",
        "La API de OpenMP se compone de tres componentes distintos. A partir de la versión 4.0:\n",
        "\n",
        "1. **Directivas del Compilador (44)**\n",
        "2. **Rutinas de Biblioteca en Tiempo de Ejecución (35)**\n",
        "3. **Variables de Entorno (13)**\n",
        "\n",
        "El desarrollador de la aplicación decide cómo emplear estos componentes. En el caso más simple, solo se necesitan algunos de ellos.\n",
        "\n",
        "#### **Directivas del Compilador:**\n",
        "Las directivas del compilador aparecen como comentarios en tu código fuente y son ignoradas por los compiladores a menos que se indique lo contrario, generalmente especificando la bandera de compilador adecuada.\n",
        "\n",
        "Las directivas del compilador de OpenMP se utilizan para varios propósitos:\n",
        "- Crear una región paralela.\n",
        "- Dividir bloques de código entre hilos.\n",
        "- Distribuir las iteraciones de los bucles entre hilos.\n",
        "- Serializar secciones de código.\n",
        "- Sincronizar el trabajo entre hilos.\n",
        "\n",
        "**Sintaxis de las directivas del compilador:**\n",
        "\n",
        "```c\n",
        "sentinel       directive-name      [clause, ...]\n",
        "```\n",
        "\n",
        "**Ejemplo en C/C++:**\n",
        "```c\n",
        "#pragma omp parallel default(shared) private(beta, pi)\n",
        "```\n",
        "\n",
        "#### **Rutinas de Biblioteca en Tiempo de Ejecución:**\n",
        "La API de OpenMP incluye un número cada vez mayor de rutinas de biblioteca en tiempo de ejecución. Estas rutinas se utilizan para diversos propósitos, como:\n",
        "\n",
        "- Establecer y consultar el número de hilos.\n",
        "- Consultar el identificador único de un hilo (ID del hilo) y el tamaño del equipo de hilos.\n",
        "- Establecer y consultar la función de hilos dinámicos.\n",
        "- Consultar si se está en una región paralela y a qué nivel.\n",
        "- Establecer y consultar el paralelismo anidado.\n",
        "- Establecer, inicializar y terminar bloqueos y bloqueos anidados.\n",
        "- Consultar el tiempo de reloj y la resolución.\n",
        "\n",
        "**Ejemplo en C/C++:**\n",
        "```c\n",
        "#include <omp.h>\n",
        "int omp_get_num_threads(void)\n",
        "```\n",
        "\n",
        "Ten en cuenta que para C/C++, generalmente debes incluir el archivo de encabezado `<omp.h>`.\n",
        "\n",
        "#### **Variables de Entorno:**\n",
        "OpenMP proporciona varias variables de entorno para controlar la ejecución del código paralelo en tiempo de ejecución. Estas variables pueden utilizarse para controlar aspectos como:\n",
        "\n",
        "- Establecer el número de hilos.\n",
        "- Especificar cómo se dividen las iteraciones de los bucles.\n",
        "- Asignar hilos a procesadores.\n",
        "- Habilitar/deshabilitar el paralelismo anidado y establecer los niveles máximos de paralelismo anidado.\n",
        "- Habilitar/deshabilitar los hilos dinámicos.\n",
        "- Establecer el tamaño de la pila de hilos.\n",
        "- Establecer la política de espera de hilos.\n",
        "\n",
        "**Ejemplo de cómo establecer variables de entorno en `bash`:**\n",
        "```bash\n",
        "export OMP_NUM_THREADS=8\n",
        "```\n",
        "\n",
        "### **Estructura General del Código OpenMP en C/C++:**\n",
        "\n",
        "```c\n",
        "#include <omp.h>\n",
        "\n",
        "main ()  {\n",
        "\n",
        "    int var1, var2, var3;\n",
        "\n",
        "    // Código secuencial\n",
        "    //      .\n",
        "    //      .\n",
        "    //      .\n",
        "\n",
        "    // Inicio de la sección paralela. Se crea un equipo de hilos.\n",
        "    // Especificar el alcance de las variables.\n",
        "\n",
        "    #pragma omp parallel private(var1, var2) shared(var3)\n",
        "    {\n",
        "        // Sección paralela ejecutada por todos los hilos.\n",
        "        //      .\n",
        "        // Otras directivas de OpenMP.\n",
        "        //      .\n",
        "        // Llamadas a la biblioteca en tiempo de ejecución.\n",
        "        //      .\n",
        "        // Todos los hilos se unen al hilo maestro y terminan.\n",
        "    }  \n",
        "\n",
        "    // Retomar el código secuencial\n",
        "    //      .\n",
        "    //      .\n",
        "\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "WwUxT4esC0vt"
      },
      "id": "WwUxT4esC0vt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uso en Programación C/C++"
      ],
      "metadata": {
        "id": "3d8vZRJKPYpd"
      },
      "id": "3d8vZRJKPYpd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo de Ejecución Fork-Join en OpenMP**\n",
        "\n",
        "OpenMP utiliza el modelo de ejecución paralelo **fork-join**. Todos los programas de OpenMP comienzan con un único hilo maestro que se ejecuta secuencialmente hasta que se encuentra con una región paralela, momento en el cual crea un equipo de hilos paralelos (*FORK*). Una vez que los hilos del equipo completan la región paralela, se sincronizan y terminan, dejando únicamente al hilo maestro para continuar la ejecución secuencial (*JOIN*).\n",
        "\n",
        "### **Ejemplo \"Hello World\" en OpenMP**\n",
        "\n",
        "Aquí se tiene un ejemplo básico que muestra cómo paralelizar un programa \"Hello World\". Primero, la versión secuencial:\n",
        "\n",
        "```c\n",
        "#include <stdio.h>\n",
        "int main() {\n",
        "    printf(\"Hello, World from just me!\\n\");\n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "Para hacer esto en paralelo (es decir, tener una serie de hilos que impriman un mensaje \"Hello World!\"), haríamos lo siguiente:\n",
        "\n",
        "```c\n",
        "#include <stdio.h>\n",
        "#include <omp.h>  \n",
        "int main() {\n",
        "    int thread_id;\n",
        "    #pragma omp parallel private(thread_id)\n",
        "    {\n",
        "        thread_id = omp_get_thread_num();\n",
        "        printf(\"Hello, World from thread %d!\\n\", thread_id);\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "### **Compilación y Ejecución de un Programa OpenMP**\n",
        "\n",
        "Para compilar y ejecutar el programa `omphello.c` anterior:\n",
        "\n",
        "```bash\n",
        "gcc -o omphello omphello.c -fopenmp\n",
        "export OMP_NUM_THREADS=4\n",
        "./omphello\n",
        "```\n",
        "\n",
        "### **Estructura General del Código OpenMP**\n",
        "\n",
        "El siguiente fragmento muestra la estructura general de un programa en C/C++ que utiliza OpenMP:\n",
        "\n",
        "```c\n",
        "#include <omp.h>\n",
        "main () {\n",
        "    int var1, var2, var3;\n",
        "    // Código secuencial\n",
        "    . . .\n",
        "\n",
        "    // Inicio de la sección paralela\n",
        "    #pragma omp parallel private(var1, var2) shared(var3)\n",
        "    {\n",
        "        /* Sección paralela ejecutada por todos los hilos */\n",
        "        . . .\n",
        "\n",
        "        /* Todos los hilos se unen al hilo maestro y terminan */\n",
        "    }\n",
        "    // Retomar el código secuencial\n",
        "    . . .\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "```\n",
        "\n",
        "Al observar este ejemplo, debes notar algunos puntos clave. Primero, es necesario incluir el encabezado de OpenMP (`omp.h`). Segundo, hay variables que se declaran fuera de la región paralela del código. Si estas variables se utilizan dentro de la región paralela, debemos determinar si son variables públicas (compartidas) o privadas.\n",
        "\n",
        "- **Variable Privada:** Cada hilo tiene su propia copia de esta variable, y los cambios realizados por un hilo no serán visibles para los otros hilos. Una variable definida dentro de la región paralela será privada por defecto.\n",
        "- **Variable Pública:** Es compartida entre todos los hilos, y cualquier cambio realizado por un hilo será visible para todos. Es importante tener precaución al permitir que varios hilos lean y escriban en la misma variable para evitar condiciones de carrera (*race conditions*).\n",
        "\n",
        "### **Bucles `for` Paralelos en OpenMP**\n",
        "\n",
        "OpenMP se puede utilizar para paralelizar fácilmente los bucles `for`. Esto solo es posible cuando las iteraciones del bucle son independientes (es decir, la ejecución de una iteración no depende del resultado de iteraciones anteriores). Aquí tienes un ejemplo de un bucle `for` secuencial:\n",
        "\n",
        "```c\n",
        "for( i=0; i < 25; i++ ) {\n",
        "    printf(\"Foo\");\n",
        "}\n",
        "```\n",
        "\n",
        "La versión paralela de este bucle es:\n",
        "\n",
        "```c\n",
        "#pragma omp parallel for\n",
        "for( i=0; i < 25; i++ ) {\n",
        "  printf(\"Foo\");\n",
        "}\n",
        "```\n",
        "\n",
        "### **Directivas de OpenMP**\n",
        "\n",
        "En las secciones anteriores se han dado ejemplos de directivas de OpenMP. El formato general de estas directivas es:\n",
        "\n",
        "```c\n",
        "#pragma omp directive-name [clause,..] newline\n",
        "```\n",
        "\n",
        "El alcance de una directiva es un bloque de declaraciones rodeadas por `{ }`. Algunas cláusulas comunes incluyen:\n",
        "\n",
        "- **if (expresión):** solo se ejecuta en paralelo si la expresión se evalúa como verdadera.\n",
        "- **private(lista):** variables privadas y locales para un hilo.\n",
        "- **shared(lista):** datos accesibles por todos los hilos.\n",
        "- **default (none|shared):** establece el comportamiento predeterminado de las variables.\n",
        "- **reduction (operador: lista):** se utiliza cuando el resultado de una región paralela es un valor único. Por ejemplo, si tenemos una matriz de enteros de la cual queremos calcular la suma, podemos hacerlo en paralelo como sigue:\n",
        "\n",
        "```c\n",
        "int sum = 0;\n",
        "#pragma omp parallel default(none) shared (n, x) \\\n",
        "  private (i) reduction(+ : sum)\n",
        "{\n",
        "    for(i = 0; i < n; i++)\n",
        "        sum = sum + x[i];\n",
        "}\n",
        "```\n",
        "\n",
        "### **Consejos Útiles**\n",
        "\n",
        "- **Sincronización de hilos en una región paralela usando `barrier`:** A veces, es necesario que todos los hilos esperen en un cierto punto del código antes de continuar. Para lograr esto, se utiliza `#pragma omp barrier`.\n",
        "\n",
        "- **Secciones `atomic` y `critical`:** Dentro de una región paralela, es posible que desees ejecutar código que solo un hilo deba ejecutar a la vez (por ejemplo, al actualizar una variable compartida). En estos casos, se debe utilizar una sección `atomic` o `critical`. Estas definen bloques de código dentro de una región paralela que serán ejecutados solo por un hilo a la vez.\n",
        "\n",
        "```c\n",
        "#pragma omp parallel shared(x)\n",
        "{\n",
        "    . . .\n",
        "\n",
        "    #pragma omp atomic\n",
        "    {\n",
        "        x++;\n",
        "    }\n",
        "    . . .\n",
        "\n",
        "    #pragma omp critical\n",
        "    {\n",
        "        // código más largo que involucra la variable x\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "- **Secciones `master` y `single`:** Dentro de una región paralela, también es posible que tengas un bloque de código que solo debe ejecutarse una vez. Esto se puede hacer con un bloque `single` (`#pragma omp single`), que significa que el siguiente bloque de código solo será ejecutado una vez por el primer hilo que lo alcance, o con un bloque `master` (`#pragma omp master`), que significa que solo será ejecutado por el hilo maestro (ID de hilo 0).\n",
        "\n",
        "### **Funciones y Variables de Entorno Útiles en OpenMP**\n",
        "\n",
        "Algunas funciones útiles que podrías querer usar en relación con OpenMP incluyen:\n",
        "\n",
        "- `omp_get_num_threads()`: Devuelve el número de hilos paralelos.\n",
        "- `omp_get_thread_num()`: Devuelve el ID único del hilo actual.\n",
        "- `omp_set_num_threads(n)`: Establece el número de hilos a utilizar en las regiones paralelas en `n`.\n",
        "\n",
        "No es necesario establecer explícitamente el número de hilos en tu código. El mismo efecto se puede lograr configurando la variable de entorno `OMP_NUM_THREADS`.\n",
        "\n"
      ],
      "metadata": {
        "id": "SThngjWxPZR9"
      },
      "id": "SThngjWxPZR9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}