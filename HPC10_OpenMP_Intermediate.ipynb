{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Computación de Alto Desempeño</h1>\n",
    "<h1 align=\"center\">OpenMP - Intermedio</h1>\n",
    "<h1 align=\"center\">2024</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "|[![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)](mailto:calvarezh@udemedellin.edu.co)||[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/HPC/blob/main/HPC10_OpenMP_Intermediate.ipynb)\n",
    "|-:|:-|--:|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sincronización en OpenMP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **¿Por qué es importante la sincronización?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se trabaja con múltiples *threads* en un programa paralelo, el acceso simultáneo a recursos compartidos (como variables globales) puede generar conflictos o resultados inesperados. Por ejemplo, si varios *threads* intentan modificar la misma variable al mismo tiempo, se puede generar una condición de carrera (más sobre esto adelante). La sincronización se utiliza para evitar estos problemas y garantizar que los *threads* trabajen de manera coordinada y ordenada.\n",
    "\n",
    "En OpenMP, hay varias herramientas para manejar la sincronización, dependiendo de lo que necesites hacer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Secciones Críticas (`#pragma omp critical`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando varios *threads* necesitan modificar una misma variable o realizar una tarea que no puede hacerse en paralelo, se utiliza una **sección crítica**. Esta asegura que solo un *thread* a la vez ejecute esa porción de código.\n",
    "\n",
    "**Ejemplo:** Modificación de una variable compartida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main() {\n",
    "    int contador = 0;\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < 1000; i++) {\n",
    "        #pragma omp critical\n",
    "        {\n",
    "            contador++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"El valor final del contador es: %d\\n\", contador);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, el acceso a la variable `contador` está protegido por `#pragma omp critical`, lo que garantiza que solo un *thread* a la vez incremente su valor. Sin la sección crítica, los resultados serían inconsistentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sección Atómica (`#pragma omp atomic`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para operaciones sencillas como sumas o restas, una sección crítica puede ser un poco \"costosa\" en términos de rendimiento. Aquí es donde la **sección atómica** se convierte en una opción mejor, ya que es más eficiente y asegura que operaciones simples como `x += 1` se ejecuten de manera atómica, es decir, sin interferencia de otros *threads*.\n",
    "\n",
    "**Ejemplo:** Incremento eficiente de una variable compartida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main() {\n",
    "    int suma = 0;\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < 1000; i++) {\n",
    "        #pragma omp atomic\n",
    "        suma += 1;\n",
    "    }\n",
    "\n",
    "    printf(\"El valor final de la suma es: %d\\n\", suma);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí usamos `#pragma omp atomic` en lugar de `critical`. Esta es una opción más eficiente cuando lo único que se necesita es garantizar que una operación simple, como un incremento, se ejecute sin interferencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Barrera (`#pragma omp barrier`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagina un grupo de *threads* corriendo a lo largo de un programa. Cada uno ejecuta su parte del trabajo a su propio ritmo. Pero, ¿qué sucede si quieres asegurarte de que todos los *threads* terminen una tarea antes de que el programa continúe? Aquí es donde entra la **barrera**.\n",
    "\n",
    "La barrera obliga a que todos los *threads* lleguen a cierto punto en el programa antes de que cualquiera de ellos pueda continuar. Es una forma de asegurarse de que todo el mundo esté sincronizado antes de pasar al siguiente paso.\n",
    "\n",
    "**Ejemplo:** Coordinación de *threads* con una barrera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main() {\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        int id = omp_get_thread_num();\n",
    "        printf(\"Thread %d: Antes de la barrera\\n\", id);\n",
    "\n",
    "        #pragma omp barrier  // Todos los threads deben llegar aquí antes de continuar\n",
    "\n",
    "        printf(\"Thread %d: Después de la barrera\\n\", id);\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, los *threads* imprimen un mensaje antes y después de la barrera. Ningún *thread* puede continuar más allá de la barrera hasta que todos los *threads* hayan llegado a ese punto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ordered (`#pragma omp ordered`)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A veces, incluso cuando ejecutas un bucle en paralelo, puede que quieras que ciertos resultados aparezcan en el mismo orden en que habrían aparecido si el bucle se ejecutara de forma secuencial. Para estos casos, puedes usar la directiva **`#pragma omp ordered`**.\n",
    "\n",
    "**Ejemplo:** Garantizar el orden en la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main() {\n",
    "    #pragma omp parallel for ordered\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        #pragma omp ordered\n",
    "        {\n",
    "            printf(\"Iteración %d\\n\", i);\n",
    "        }\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque el bucle se ejecuta en paralelo, gracias a `#pragma omp ordered`, la salida del programa sigue apareciendo en orden secuencial. Esta directiva es útil cuando el orden de ejecución es importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tareas (Tasking) en OpenMP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **¿Qué es una tarea?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos casos, el paralelismo en bucles no es suficiente. Necesitamos dividir el trabajo en **tareas**, que son bloques de código independientes que pueden ejecutarse en paralelo. OpenMP ofrece la capacidad de crear tareas que son distribuidas dinámicamente entre los *threads* disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creación de Tareas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tareas en OpenMP son bloques de trabajo que pueden ser creados de forma dinámica y ejecutados por cualquier *thread*. Esto permite mucha flexibilidad, especialmente cuando las iteraciones de un bucle no son homogéneas, es decir, cuando algunas tareas pueden tomar más tiempo que otras.\n",
    "\n",
    "**Ejemplo:** Creación y ejecución de tareas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "void tarea(int id) {\n",
    "    printf(\"Ejecutando tarea %d\\n\", id);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp single\n",
    "        {\n",
    "            for (int i = 0; i < 10; i++) {\n",
    "                #pragma omp task\n",
    "                tarea(i);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, un solo *thread* crea las tareas (`#pragma omp single`), pero cualquier *thread* disponible puede ejecutar esas tareas. Esto es útil cuando las tareas son independientes y no tienen que ejecutarse en ningún orden particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tareas con dependencias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos casos, puede que una tarea dependa del resultado de otra. Por ejemplo, no puedes procesar un archivo hasta que haya sido descargado. Para estos casos, OpenMP permite definir dependencias entre tareas.\n",
    "\n",
    "**Ejemplo:** Tareas con dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main() {\n",
    "    int x = 0;\n",
    "\n",
    "    #pragma omp parallel\n",
    "    {\n",
    "        #pragma omp single\n",
    "        {\n",
    "            // Tarea 1: Modifica el valor de x\n",
    "            #pragma omp task depend(out:x)\n",
    "            {\n",
    "                x = 10;\n",
    "                printf(\"Tarea 1: x = %d\\n\", x);\n",
    "            }\n",
    "\n",
    "            // Tarea 2: Depende del valor de x\n",
    "            #pragma omp task depend(in:x)\n",
    "            {\n",
    "                printf(\"Tarea 2 (después de Tarea 1): x = %d\\n\", x);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, la segunda tarea se ejecuta solo después de que la primera haya completado su operación sobre `x`, gracias a las dependencias especificadas con `depend`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Condiciones de Carrera y Bloqueos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **¿Qué es una Condición de Carrera?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una **condición de carrera** ocurre cuando dos o más *threads* acceden a una variable compartida al mismo tiempo y al menos uno de ellos la modifica. Esto puede llevar a resultados impredecibles, ya que no hay garantías de en qué orden los *threads* accederán a la variable.\n",
    "\n",
    "**Ejemplo:** Condición de carrera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main() {\n",
    "    int x = 0;\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < 1000; i++) {\n",
    "        x += 1;  // Condición de carrera potencial\n",
    "    }\n",
    "\n",
    "    printf(\"Valor de x: %d\\n\", x);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, varios *threads* están modificando la variable `x` al mismo tiempo, lo que provoca un resultado incorrecto debido a la condición de carrera. Dependiendo de la máquina y el entorno de ejecución, el valor final de `x` será incorrecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Solución: Sección Crítica o Atómica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar condiciones de carrera, necesitamos asegurarnos de que solo un *thread* a la vez modifique la variable compartida.\n",
    "\n",
    "**Ejemplo:** Solución con sección atómica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main() {\n",
    "    int x = 0;\n",
    "\n",
    "\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < 1000; i++) {\n",
    "        #pragma omp atomic\n",
    "        x += 1;  // Actualización atómica\n",
    "    }\n",
    "\n",
    "    printf(\"Valor de x: %d\\n\", x);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `#pragma omp atomic`, evitamos la condición de carrera y garantizamos que el valor de `x` se actualice correctamente sin interferencias de otros *threads*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Paralelismo SIMD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **¿Qué es el Paralelismo SIMD?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMD (Single Instruction, Multiple Data) es una técnica que permite ejecutar una única instrucción en múltiples datos al mismo tiempo. Es especialmente útil para trabajar con vectores o arreglos grandes, y puede acelerar significativamente ciertos cálculos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vectorización con OpenMP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenMP permite vectorizar bucles con la directiva `#pragma omp simd`, forzando al compilador a ejecutar las operaciones de manera paralela en múltiples elementos del arreglo.\n",
    "\n",
    "**Ejemplo:** Paralelismo SIMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "int main() {\n",
    "    int n = 100;\n",
    "    float a[n], b[n];\n",
    "\n",
    "    // Inicialización de los arreglos\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        a[i] = i * 1.0f;\n",
    "    }\n",
    "\n",
    "    // Paralelismo SIMD: Multiplicar todos los elementos del arreglo\n",
    "    #pragma omp simd\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        b[i] = a[i] * 2.0f;\n",
    "    }\n",
    "\n",
    "    // Mostrar algunos resultados\n",
    "    for (int i = 0; i < 10; i++) {\n",
    "        printf(\"b[%d] = %f\\n\", i, b[i]);\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí estamos utilizando `#pragma omp simd` para paralelizar el bucle de multiplicación, haciendo que se procesen varios elementos del arreglo `a[]` en paralelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ejercicios**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 1: Suma de series paralelas con condiciones de carrera -** Dado un vector de números aleatorios, paraleliza el cálculo de la suma de sus elementos utilizando OpenMP. Inicialmente, introduce una condición de carrera para que los estudiantes vean el problema. Luego, deben solucionarlo utilizando una sección crítica o una directiva atómica.\n",
    "\n",
    "```pseudocode\n",
    "- Generar un vector aleatorio de 1,000,000 números.\n",
    "- Calcular la suma de los elementos en paralelo.\n",
    "- Corregir la condición de carrera usando `#pragma omp critical` o `#pragma omp atomic`.\n",
    "```\n",
    "\n",
    "**Desafío adicional**: Extiende el programa para que también calcule la suma cuadrada (sumar el cuadrado de cada número del vector) en paralelo, garantizando la sincronización adecuada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2: Paralelización del cálculo de la norma de un vector** - Implementar paralelismo en el cálculo de la **norma de un vector** en un espacio N-dimensional, aplicando la directiva `#pragma omp simd` para optimizar el cálculo.\n",
    "\n",
    "La norma de un vector $\\vec{v}$ de dimensión N se calcula como:\n",
    "\n",
    "$$\n",
    "\\|\\vec{v}\\| = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^2}\n",
    "$$\n",
    "\n",
    "Escribe un programa en C que:\n",
    "1. Genere un vector con N componentes aleatorias.\n",
    "2. Calcule la norma utilizando paralelismo SIMD para los cuadrados de los elementos y sincronización para la suma total.\n",
    "\n",
    "```c\n",
    "// Pseudocódigo\n",
    "- Inicializar un vector con números aleatorios.\n",
    "- Paralelizar el cálculo de la suma de los cuadrados utilizando `#pragma omp simd`.\n",
    "- Sincronizar los resultados y calcular la raíz cuadrada.\n",
    "```\n",
    "\n",
    "**Desafío adicional**: Aumentar el tamaño del vector a 10 millones de elementos y observar el impacto en el tiempo de ejecución antes y después de la vectorización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3: Movimiento rectilíneo uniformemente acelerado (MRUA) -** Modela el movimiento de un objeto bajo **movimiento rectilíneo uniformemente acelerado (MRUA)**, donde el objeto parte de una posición inicial con una velocidad inicial, y se actualizan la posición y la velocidad en función de la aceleración $a$. Utiliza OpenMP para calcular las posiciones y velocidades en varios puntos de tiempo de forma paralela, pero respetando las dependencias (cada posición futura depende de la posición anterior).\n",
    "\n",
    "Las fórmulas para MRUA son:\n",
    "$$\n",
    "v(t) = v_0 + at\n",
    "$$\n",
    "$$\n",
    "x(t) = x_0 + v_0 t + \\frac{1}{2} a t^2\n",
    "$$\n",
    "\n",
    "```c\n",
    "// Pseudocódigo\n",
    "- Inicializar valores de velocidad y posición.\n",
    "- Crear tareas para calcular posición y velocidad en diferentes tiempos t.\n",
    "- Utilizar dependencias para asegurar que cada tarea respete los cálculos previos.\n",
    "```\n",
    "\n",
    "**Desafío adicional**: Agrega un factor de fricción al sistema y paraleliza tanto el cálculo de la velocidad como de la posición.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 4: Multiplicación de matrices grandes -** Implementar la multiplicación de dos matrices grandes utilizando el paralelismo en bucles de OpenMP. Este ejercicio ayudará a reforzar la idea de cómo se pueden paralelizar las operaciones de matrices, optimizando el tiempo de ejecución en grandes dimensiones.\n",
    "\n",
    "Escribe un programa en C que realice la multiplicación de dos matrices \\(A \\times B = C\\) de tamaño \\(N \\times N\\). Paraleliza el cálculo de los elementos de la matriz resultante \\(C\\).\n",
    "\n",
    "```c\n",
    "// Pseudocódigo\n",
    "- Inicializar matrices A y B de tamaño N x N.\n",
    "- Implementar la multiplicación de matrices tradicional.\n",
    "- Paralelizar los bucles utilizando `#pragma omp parallel for`.\n",
    "- Comparar el rendimiento para N = 500, 1000 y 2000.\n",
    "```\n",
    "\n",
    "**Desafío adicional**: Aplicar optimización con `#pragma omp collapse` para paralelizar bucles anidados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 5: Cálculo de Pi usando el método Monte Carlo -** Este método consiste en generar puntos aleatorios dentro de un cuadrado y contar cuántos caen dentro de un círculo inscrito. La razón entre los puntos dentro del círculo y el total de puntos generados aproxima el valor de $\\pi$.\n",
    "\n",
    "Escribe un programa que:\n",
    "1. Genere puntos aleatorios.\n",
    "2. Determine cuántos de ellos caen dentro del círculo.\n",
    "3. Calcule $\\pi$ en paralelo.\n",
    "\n",
    "```c\n",
    "// Pseudocódigo\n",
    "- Generar puntos aleatorios en el plano (x, y).\n",
    "- Contar los puntos que caen dentro del círculo (x^2 + y^2 <= 1).\n",
    "- Paralelizar el proceso de conteo utilizando `#pragma omp parallel for`.\n",
    "```\n",
    "\n",
    "**Desafío adicional**: Comparar la eficiencia de una implementación que utilice reducción (`reduction`) frente a una implementación con tareas (`task`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 6: Paralelismo SIMD en el cálculo de producto punto -** Utilizar la directiva `#pragma omp simd` para optimizar el cálculo del **producto punto** de dos vectores grandes. Escribe un programa que paralelice el cálculo del producto punto entre dos vectores de tamaño 10 millones de elementos.\n",
    "\n",
    "```c\n",
    "// Pseudocódigo\n",
    "- Inicializar dos vectores con números aleatorios.\n",
    "- Implementar el cálculo del producto punto en un bucle simple.\n",
    "- Utilizar `#pragma omp simd` para vectorizar el cálculo.\n",
    "```\n",
    "\n",
    "**Desafío adicional**: Implementa la misma operación utilizando `reduction` y compara la eficiencia de ambas versiones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 7: Resolución de un sistema de ecuaciones lineales con Gauss-Seidel -** Implementar el método de Gauss-Seidel para resolver un sistema de ecuaciones lineales y paralelizar las iteraciones. Escribe un programa que utilice el método iterativo de Gauss-Seidel para resolver un sistema de ecuaciones de la forma $Ax = b$.\n",
    "\n",
    "```c\n",
    "// Pseudocódigo\n",
    "- Inicializar una matriz A y un vector b.\n",
    "- Implementar el método de Gauss-Seidel.\n",
    "- Paralelizar el cálculo utilizando OpenMP.\n",
    "```\n",
    "\n",
    "**Desafío adicional**: Usar la directiva `#pragma omp task` para paralelizar las actualizaciones de cada fila en cada iteración.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
