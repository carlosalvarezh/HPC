{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b06738",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Computación de Alto Desempeño</h1>\n",
    "<h1 align=\"center\">Diseño de Programas Paralelos</h1>\n",
    "<h1 align=\"center\">2024</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32776e",
   "metadata": {},
   "source": [
    "*** \n",
    "|[![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)](mailto:calvarezh@udemedellin.edu.co)||[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/HPC/blob/main/HPC03_DisenoProgramasParalelo.ipynb)\n",
    "|-:|:-|--:|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d6c30",
   "metadata": {},
   "source": [
    "# Aviso Legal sobre estas Notas de Clase\n",
    "\n",
    "Las presentes notas de clase han sido elaboradas con fines educativos y como material de apoyo para el aprendizaje y comprensión de la computación paralela. Estas notas están basadas en información y contenidos derivados del tutorial *[\"Introduction to Parallel Computing Tutorial\"](https://hpc.llnl.gov/documentation/tutorials/introduction-parallel-computing-tutorial)* disponible en el sitio web del *Laboratorio Nacional Lawrence Livermore* (https://hpc.llnl.gov/). Este material se proporciona tal cual, sin garantías de exactitud completa o de la aplicabilidad para un fin particular.\n",
    "\n",
    "A pesar de que se ha hecho un esfuerzo por asegurar la precisión y utilidad de estas notas, los usuarios deben tener en cuenta que los conceptos, aplicaciones y técnicas de la computación paralela están en constante evolución, y se recomienda consultar múltiples fuentes y la documentación oficial más actual para obtener la información más reciente y completa.\n",
    "\n",
    "Por favor, considere que cualquier ejemplo, referencia o cita de \"Introducción a la Computación Paralela\" se proporciona con el objetivo de ilustrar los conceptos y principios básicos de la computación paralela y no debe considerarse como una guía exhaustiva o definitiva sobre el tema.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f6488c",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel00.jpg?raw=true\" width=\"500\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4299db",
   "metadata": {},
   "source": [
    "## Diseño de Programas Paralelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd3e33",
   "metadata": {},
   "source": [
    "### Paralelización Automática vs. Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaba9d4",
   "metadata": {},
   "source": [
    "El diseño y desarrollo de programas paralelos ha sido tradicionalmente un proceso muy manual. Generalmente, el programador es responsable tanto de identificar como de implementar el paralelismo.\n",
    "\n",
    "Desarrollar códigos paralelos manualmente es a menudo un proceso que consume tiempo, es complejo, propenso a errores y requiere iteraciones.\n",
    "\n",
    "Durante varios años, han estado disponibles diversas herramientas para asistir al programador en la conversión de programas seriales a programas paralelos. El tipo de herramienta más común utilizado para paralelizar automáticamente un programa serial es un compilador paralelizante o un preprocesador.\n",
    "\n",
    "Un compilador paralelizante generalmente funciona de dos maneras diferentes:\n",
    "\n",
    "\n",
    "***Completamente Automático***\n",
    "- El compilador analiza el código fuente e identifica oportunidades para el paralelismo.\n",
    "- El análisis incluye la identificación de inhibidores del paralelismo y posiblemente una ponderación de costos sobre si el paralelismo realmente mejoraría el rendimiento.\n",
    "- Los bucles (do, for) son el objetivo más frecuente para la paralelización automática.\n",
    "\n",
    "***Dirigido por el Programador***\n",
    "- Utilizando \"directivas de compilador\" o posiblemente banderas de compilador, el programador le indica explícitamente al compilador cómo paralelizar el código.\n",
    "- Puede ser usado en conjunto con algún grado de paralelización automática también.\n",
    "\n",
    "La paralelización generada por el compilador más común se realiza usando memoria compartida en el nodo y hilos (como OpenMP).\n",
    "\n",
    "Si estás comenzando con un código serial existente y tienes restricciones de tiempo o presupuesto, entonces la paralelización automática puede ser la respuesta. Sin embargo, hay varias advertencias importantes que se aplican a la paralelización automática:\n",
    "\n",
    "- Puede producir resultados incorrectos.\n",
    "- El rendimiento puede degradarse.\n",
    "- Es mucho menos flexible que la paralelización manual.\n",
    "- Limitada a un subconjunto (principalmente bucles) del código.\n",
    "- Puede que no paralelice el código si el análisis del compilador sugiere que hay inhibidores o el código es demasiado complejo.\n",
    "\n",
    "El resto de esta sección se aplica al método manual de desarrollo de códigos paralelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f789d2",
   "metadata": {},
   "source": [
    "### Comprender el Problema y el Programa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68866f78",
   "metadata": {},
   "source": [
    "$$\\text{Programas = algoritmos + datos + (hardware)}$$\n",
    "\n",
    "Sin duda, el primer paso en el desarrollo de software paralelo es primero comprender el problema que deseas resolver en paralelo. Si estás comenzando con un programa serial, esto significa entender también el código existente.\n",
    "Antes de dedicar tiempo en un intento de desarrollar una solución paralela para un problema, determina si el problema es uno que realmente se pueda paralelizar.\n",
    "\n",
    "- **Ejemplo de un problema fácil de paralelizar:** Calcular la energía potencial para cada una de varias miles de conformaciones independientes de una molécula. Una vez hecho esto, encontrar la conformación de energía mínima. Este problema puede resolverse en paralelo. Cada una de las conformaciones moleculares es determinable independientemente. El cálculo de la conformación de energía mínima también es un problema paralelizable.\n",
    "\n",
    "- **Ejemplo de un problema y algoritmo con poco o ningún paralelismo:** Cálculo de los primeros $10,000$ miembros de la serie de Fibonacci $(0,1,1,2,3,5,8,13,21, \\ldots)$ mediante el uso de la fórmula:\n",
    "\n",
    "$$F(n) = F(n-1) + F(n-2)$$\n",
    "\n",
    "El cálculo del valor de $F(n)$ utiliza los de $F(n-1)$ y $F(n-2)$, que deben ser calculados primero.\n",
    "\n",
    "Un ejemplo de un algoritmo paralelo para resolver este problema (usando la fórmula de Binet):\n",
    "\n",
    "$$F_n = \\frac{\\varphi^n - (-\\varphi)^{-n}}{\\sqrt{5}} = \\frac{\\varphi^n - (-\\varphi)^{-n}}{2\\varphi - 1} $$\n",
    "\n",
    "  donde\n",
    "\n",
    "$$\\varphi = \\frac{1 + \\sqrt{5}}{2} \\approx 1.6180339887 \\ldots $$\n",
    "\n",
    "- **Identificar los puntos críticos del programa:**  \n",
    "  - Conoce dónde se está realizando la mayor parte del trabajo real. La mayoría de los programas científicos y técnicos generalmente realizan la mayor parte de su trabajo en pocos lugares.\n",
    "  - Los perfiles y herramientas de análisis de rendimiento pueden ayudar aquí.\n",
    "  - Concéntrate en paralelizar los puntos críticos e ignora aquellas secciones del programa que representan poco uso de CPU.\n",
    "\n",
    "- **Identificar cuellos de botella en el programa:**  \n",
    "  - ¿Hay áreas que son desproporcionadamente lentas o causan que el trabajo paralelizable se detenga o se posponga? Por ejemplo, las operaciones de I/O generalmente ralentizan un programa.\n",
    "  - Puede ser posible reestructurar el programa o usar un algoritmo diferente para reducir o eliminar áreas lentas innecesarias.\n",
    "\n",
    "- **Identificar inhibidores al paralelismo.** Una clase común de inhibidor es la dependencia de datos, como se demostró con la secuencia de Fibonacci anterior.  \n",
    "  - Investiga otros algoritmos si es posible. Esto puede ser la consideración más importante al diseñar una aplicación paralela.\n",
    "  - Aprovecha el software paralelo de terceros optimizado y las bibliotecas matemáticas altamente optimizadas disponibles de proveedores líderes (ESSL de IBM, MKL de Intel, AMCL de AMD, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9685f3",
   "metadata": {},
   "source": [
    "### Particionamiento en Programación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d17e8",
   "metadata": {},
   "source": [
    "El particionamiento es uno de los primeros pasos en el diseño de un programa paralelo y consiste en dividir el problema en \"trozos\" discretos de trabajo que pueden ser distribuidos a múltiples tareas. Este proceso es conocido como descomposición o particionamiento y es fundamental para la eficiencia y efectividad de las soluciones paralelas. Existen dos formas básicas de particionar el trabajo computacional entre las tareas paralelas: la descomposición de dominio y la descomposición funcional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2053db",
   "metadata": {},
   "source": [
    "#### Descomposición de Dominio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405e046",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel36.gif?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "En este tipo de particionamiento, los datos asociados con un problema son descompuestos. Cada tarea paralela entonces trabaja en una porción de los datos. \n",
    "\n",
    "**Maneras de particionar datos:**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel37.gif?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "- **Por Bloques:** Los datos se dividen en bloques contiguos, cada uno asignado a una tarea diferente. Esto es común en problemas donde los datos se pueden segmentar naturalmente, como en simulaciones espaciales o temporales.\n",
    "  \n",
    "- **Por Ciclos:** Los datos se distribuyen en un patrón cíclico entre las tareas, lo que puede ayudar a balancear la carga de trabajo cuando las operaciones realizadas sobre los datos varían en complejidad.\n",
    "  \n",
    "- **Por Dispersión:** Los datos se dividen de manera que cada tarea recibe fragmentos que están dispersos a través del conjunto de datos completo. Esto puede ser útil en situaciones donde la interacción entre elementos de datos es compleja y no se limita a áreas contiguas.\n",
    "\n",
    "La descomposición de dominio es especialmente útil en problemas que se basan en la manipulación de grandes volúmenes de datos, como en el procesamiento de imágenes, simulaciones de fluidos, y análisis de grandes conjuntos de datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836992c9",
   "metadata": {},
   "source": [
    "#### Descomposición Funcional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a901fc8",
   "metadata": {},
   "source": [
    "En este enfoque, el foco está en la computación que debe ser realizada más que en los datos manipulados por la computación. El problema se descompone según el trabajo que debe realizarse. Cada tarea realiza entonces una porción del trabajo general.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel38.gif?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "**Características de la descomposición funcional:**\n",
    "- **División por Tareas:** El problema se divide en diferentes funciones o tareas específicas, cada una realizada por diferentes procesos o hilos.\n",
    "  \n",
    "- **Especialización:** Cada tarea paralela se especializa en una función particular, lo cual puede llevar a una mayor eficiencia en tareas que requieren habilidades o recursos específicos.\n",
    "  \n",
    "- **Independencia:** Las tareas son a menudo independientes o tienen interdependencias mínimas, lo que reduce la necesidad de sincronización y comunicación entre tareas.\n",
    "\n",
    "La descomposición funcional se presta bien a problemas que pueden ser divididos en diferentes tareas que son relativamente independientes y pueden ser ejecutadas concurrentemente, como en sistemas de manejo de transacciones, donde diferentes tareas pueden manejar diferentes aspectos de un proceso de negocio.\n",
    "\n",
    "El éxito del particionamiento en programación paralela depende en gran medida de la naturaleza del problema y de cómo se descomponen los datos o las funciones. Una buena estrategia de particionamiento maximiza la eficiencia del paralelismo minimizando la comunicación necesaria entre tareas y equilibrando la carga de trabajo entre los procesadores. Identificar el tipo adecuado de particionamiento es crucial y puede variar significativamente de un problema a otro, influenciado por los objetivos de rendimiento y las características específicas del sistema computacional utilizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b157e",
   "metadata": {},
   "source": [
    "### Comunicaciones en Programación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b69303",
   "metadata": {},
   "source": [
    "#### ¿Quién necesita comunicaciones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848442f",
   "metadata": {},
   "source": [
    "La necesidad de comunicación entre tareas depende del problema:\n",
    "\n",
    "**No Necesitas Comunicaciones**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel42.gif?raw=true\" width=\"200\" />\n",
    "</p>\n",
    "\n",
    "- Algunos tipos de problemas pueden descomponerse y ejecutarse en paralelo sin apenas necesidad de que las tareas compartan datos. A estos problemas se les suele llamar paralelos embarazosamente - requieren poca o ninguna comunicación.\n",
    "- **Ejemplo:** Imagina una operación de procesamiento de imagen donde cada píxel en una imagen en blanco y negro necesita invertir su color. Los datos de la imagen se pueden distribuir fácilmente a múltiples tareas que actúan independientemente unas de otras para realizar su parte del trabajo.\n",
    "\n",
    "**Necesitas Comunicaciones**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel43.gif?raw=true\" width=\"200\" />\n",
    "</p>\n",
    "\n",
    "- La mayoría de las aplicaciones paralelas no son tan simples y sí requieren que las tareas compartan datos entre sí.\n",
    "- **Ejemplo:** Un problema de difusión de calor en 2-D requiere que una tarea conozca las temperaturas calculadas por las tareas que tienen datos adyacentes. Los cambios en los datos vecinos tienen un efecto directo en los datos de la tarea.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230e982",
   "metadata": {},
   "source": [
    "#### Factores a Considerar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf180638",
   "metadata": {},
   "source": [
    "Hay varios factores importantes a considerar al diseñar las comunicaciones inter-tareas de tu programa:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f886ac1",
   "metadata": {},
   "source": [
    "**Sobrecarga de Comunicación (overhead)**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel44.jpeg?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "- La comunicación inter-tareas casi siempre implica sobrecarga.\n",
    "- Ciclos de máquina y recursos que podrían usarse para la computación se usan en cambio para empaquetar y transmitir datos.\n",
    "- Las comunicaciones frecuentemente requieren algún tipo de sincronización entre tareas, lo que puede resultar en que las tareas pasen tiempo \"esperando\" en lugar de trabajar.\n",
    "- El tráfico de comunicación competidor puede saturar el ancho de banda de red disponible, agravando aún más los problemas de rendimiento.\n",
    "\n",
    "**Latencia vs. Ancho de Banda**\n",
    "- **Latencia:** Es el tiempo que tarda en enviarse un mensaje mínimo (de 0 bytes) de un punto A a un punto B. Comúnmente expresada en microsegundos.\n",
    "- **Ancho de Banda:** Es la cantidad de datos que se pueden comunicar por unidad de tiempo. Comúnmente expresado en megabytes/seg o gigabytes/seg.\n",
    "- Enviar muchos mensajes pequeños puede causar que la latencia domine las sobrecargas de comunicación. A menudo es más eficiente empaquetar mensajes pequeños en un mensaje más grande, aumentando así el ancho de banda efectivo de las comunicaciones.\n",
    "\n",
    "**Visibilidad de las Comunicaciones**\n",
    "- En el **Modelo de Paso de Mensajes**, las comunicaciones son explícitas y generalmente bastante visibles y bajo el control del programador.\n",
    "- En el **Modelo de Paralelismo de Datos**, las comunicaciones a menudo ocurren de manera transparente para el programador, especialmente en arquitecturas de memoria distribuida. El programador puede no saber exactamente cómo se están realizando las comunicaciones inter-tareas.\n",
    "\n",
    "**Comunicaciones Sincrónicas vs. Asincrónicas**\n",
    "- **Sincrónicas:** Requieren algún tipo de \"apretón de manos\" entre tareas que comparten datos. Esto puede estar explícitamente estructurado en el código por el programador.\n",
    "- **Asincrónicas:** Permiten que las tareas transfieran datos independientemente una de otra. Por ejemplo, la tarea 1 puede preparar y enviar un mensaje a la tarea 2 y luego comenzar inmediatamente a realizar otro trabajo.\n",
    "\n",
    "**Ámbito de las Comunicaciones**\n",
    "\n",
    "- Saber qué tareas deben comunicarse entre sí es crítico durante la etapa de diseño de un código paralelo. Ambos ámbitos descritos a continuación pueden implementarse de manera sincrónica o asincrónica.\n",
    "  - **Punto a Punto:** Involucra dos tareas con una tarea actuando como el emisor/productor de datos, y la otra como el receptor/consumidor.\n",
    "  - **Colectiva:** Involucra el intercambio de datos entre más de dos tareas, que a menudo se especifican como miembros de un grupo común o colectivo.\n",
    "  \n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel45.PNG?raw=true\" width=\"450\" />\n",
    "</p>\n",
    "\n",
    "La imagen muestra cuatro patrones de comunicación comunes en la programación paralela y el procesamiento distribuido: broadcast, scatter, gather y reduction. Estos patrones son fundamentales en la implementación eficiente de algoritmos paralelos para la distribución y recopilación de datos, así como para la combinación de resultados.\n",
    "\n",
    "- ***[Broadcast](https://www.cs.utexas.edu/users/AustinVilla/legged/papers/BroadcastProgrammingModels.pdf) (Difusión o Transmisión):*** Implica la distribución de datos desde un solo proceso (a menudo denominado el \"root\") a todos los demás procesos en un grupo. En un contexto de MPI (Message Passing Interface), por ejemplo, un valor o un conjunto de valores se envía desde un proceso fuente a todos los procesos dentro de un comunicador. Es útil cuando todos los procesos necesitan una copia idéntica de ciertos datos para realizar cálculos paralelos, como una constante necesaria para cálculos o una semilla para generadores de números aleatorios.\n",
    "\n",
    "- ***[Scatter](https://www.gaurgaurav.com/patterns/scatter-gather/) (Dispersión o Distribución):*** Es un patrón donde el proceso root reparte segmentos diferentes y generalmente no superpuestos de un arreglo de datos a cada uno de los procesos en el grupo, incluido él mismo si es necesario. Este patrón es efectivo cuando se distribuye un arreglo grande entre varios procesos para su procesamiento paralelo, donde cada proceso trabaja en una parte del arreglo.\n",
    "\n",
    "- ***Gather (Recolección o Agrupamiento):*** Es el proceso inverso a scatter. En lugar de distribuir datos, gather los colecta de todos los procesos en el grupo y los reúne en un único proceso root. Cada proceso envía su segmento de datos al proceso root, que luego los ensambla en un único conjunto de datos ordenado. Se utiliza a menudo al final de una operación paralela para recopilar resultados parciales de cada proceso y unirlos en un resultado final o para realizar un análisis posterior.\n",
    "\n",
    "- ***[Reduction](https://en.wikipedia.org/wiki/Reduction_operator) (Reducción):*** Es un patrón de comunicación que combina los elementos de los datos de todos los procesos en el grupo utilizando una operación especificada (como sumar, maximizar, minimizar) y pasa el resultado combinado a todos los procesos o solo al proceso root. Se utiliza comúnmente para operaciones como calcular la suma de los elementos generados por cada proceso, encontrar el máximo o mínimo valor, o cualquier otra operación de reducción que necesite ser aplicada sobre los datos distribuidos entre los procesos.\n",
    "\n",
    "En la imagen, los colores y las formas representan los datos específicos manejados por cada operación: broadcast muestra una pieza de información que se comparte desde un solo proceso a todos los demás; scatter muestra cómo se distribuye un conjunto de datos a diferentes procesos; gather representa la colecta de diferentes conjuntos de datos de vuelta al proceso root; y reduction ilustra cómo los datos de varios procesos se combinan en un solo resultado que puede ser repartido entre todos los procesos o acumulado en el proceso root.\n",
    "\n",
    "Cada uno de estos patrones es esencial en situaciones donde la coordinación y la eficiencia en la manipulación de datos son críticas para el rendimiento y la exactitud de los cálculos paralelos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Eficiencia de las Comunicaciones**\n",
    "- A menudo, el programador tiene opciones que pueden afectar el rendimiento de las comunicaciones. Elegir una plataforma con una red más rápida puede ser una opción.\n",
    "\n",
    "**Sobrecarga y Complejidad**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel46.gif?raw=true\" width=\"450\" />\n",
    "</p>\n",
    "\n",
    "- Finalmente, ¡ten en cuenta que esta es solo una lista parcial de cosas a considerar!\n",
    "\n",
    "Entender estos factores y cómo influyen en las comunicaciones dentro de un programa paralelo es crucial para el diseño eficiente de software que maximice el rendimiento mientras minimiza los cuellos de botella y la sobrecarga."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4450ec",
   "metadata": {},
   "source": [
    "### Sincronización en Programación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a9661",
   "metadata": {},
   "source": [
    "La gestión de la secuencia de trabajo y de las tareas que la realizan es una consideración de diseño crítica para la mayoría de los programas paralelos.\n",
    "\n",
    "- Puede ser un factor significativo en el rendimiento del programa (o la falta de él).\n",
    "- A menudo requiere \"serialización\" de segmentos del programa.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel47.jpeg?raw=true\" width=\"250\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691dad15",
   "metadata": {},
   "source": [
    "#### Tipos de Sincronización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559f3d0",
   "metadata": {},
   "source": [
    "**Barrera (Barrier)**\n",
    "- Generalmente implica que todas las tareas están involucradas.\n",
    "- Cada tarea ejecuta su trabajo hasta que alcanza la barrera. Entonces se detiene o \"bloquea\".\n",
    "- Cuando la última tarea alcanza la barrera, todas las tareas se sincronizan.\n",
    "- Lo que sucede a partir de aquí varía. A menudo, se debe hacer una sección de trabajo serial. En otros casos, las tareas se liberan automáticamente para continuar su trabajo.\n",
    "\n",
    "**Bloqueo / Semáforo (Lock / Semaphore)**\n",
    "- Puede involucrar a cualquier número de tareas.\n",
    "- Típicamente usado para serializar (proteger) el acceso a datos globales o una sección de código. Solo una tarea a la vez puede usar (poseer) el bloqueo / semáforo / bandera.\n",
    "- La primera tarea en adquirir el bloqueo lo \"establece\". Esta tarea puede entonces acceder de manera segura (serial) a los datos o código protegidos.\n",
    "- Otras tareas pueden intentar adquirir el bloqueo pero deben esperar hasta que la tarea que posee el bloqueo lo libere.\n",
    "- Puede ser bloqueante o no bloqueante.\n",
    "\n",
    "**Operaciones de Comunicación Sincrónicas**\n",
    "- Involucra solo a aquellas tareas que ejecutan una operación de comunicación.\n",
    "- Cuando una tarea realiza una operación de comunicación, se requiere alguna forma de coordinación con las otras tarea(s) que participan en la comunicación. Por ejemplo, antes de que una tarea pueda realizar una operación de envío, primero debe recibir una confirmación de la tarea receptora de que está bien enviar.\n",
    "- Discutido previamente en la sección de Comunicaciones.\n",
    "\n",
    "***Consideraciones Adicionales***\n",
    "\n",
    "- **Interbloqueo (Deadlock):** Ocurre cuando dos o más tareas esperan indefinidamente por recursos o eventos que están siendo bloqueados por las otras tareas.\n",
    "- **Inanición (Starvation):** Una tarea nunca adquiere el acceso necesario a los recursos debido a que otros procesos están continuamente siendo preferidos.\n",
    "- **Coordinación de Tareas:** Implica gestionar el orden y el tiempo en el que varias tareas acceden a recursos compartidos para evitar inconsistencias y errores.\n",
    "\n",
    "La sincronización eficiente es crucial para asegurar la integridad de los datos y el comportamiento correcto de un programa paralelo. Sin embargo, también puede ser una fuente de reducción de rendimiento si no se implementa cuidadosamente, ya que puede aumentar el tiempo de inactividad de las tareas y limitar la concurrencia. La elección entre diferentes mecanismos de sincronización dependerá del problema específico, el modelo de programación paralela y las características de la arquitectura de hardware en uso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576900b",
   "metadata": {},
   "source": [
    "### Dependencias de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296e1673",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c4551",
   "metadata": {},
   "source": [
    "Una dependencia existe entre instrucciones de un programa cuando el orden de ejecución de las instrucciones afecta los resultados del programa.\n",
    "Una dependencia de datos resulta del uso múltiple de la misma ubicación(es) de almacenamiento por diferentes tareas.\n",
    "Las dependencias son importantes en la programación paralela porque son uno de los principales inhibidores del paralelismo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel48.jpeg?raw=true\" width=\"200\" />\n",
    "</p>\n",
    "\n",
    "Veamos algunos ejemplos:\n",
    "\n",
    "**Dependencia de Datos Llevada por Bucle (Loop Carried Data Dependence):**\n",
    "```fortran\n",
    "DO J = MYSTART,MYEND\n",
    "   A(J) = A(J-1) * 2.0\n",
    "END DO\n",
    "```\n",
    "El valor de `A(J-1)` debe ser computado antes del valor de `A(J)`, por lo tanto, `A(J)` exhibe una dependencia de datos en `A(J-1)`. El paralelismo está inhibido.\n",
    "Si la Tarea 2 tiene `A(J)` y la tarea 1 tiene `A(J-1)`, para calcular el valor correcto de `A(J)` es necesario:\n",
    "- En arquitecturas de memoria distribuida - la tarea 2 debe obtener el valor de `A(J-1)` de la tarea 1 después de que esta termine su cálculo.\n",
    "- En arquitecturas de memoria compartida - la tarea 2 debe leer `A(J-1)` después de que la tarea 1 lo actualice.\n",
    "\n",
    "**Dependencia de Datos Independiente de Bucle (Loop Independent Data Dependence):**\n",
    "```plaintext\n",
    "tarea 1        tarea 2\n",
    "------        ------\n",
    "X = 2         X = 4\n",
    "  .             .\n",
    "  .             .\n",
    "Y = X**2      Y = X**3\n",
    "```\n",
    "Al igual que con el ejemplo anterior, el paralelismo está inhibido. El valor de `Y` depende de:\n",
    "- En arquitecturas de memoria distribuida - si o cuándo el valor de `X` se comunica entre las tareas.\n",
    "- En arquitecturas de memoria compartida - qué tarea almacena el valor de `X` por última vez.\n",
    "\n",
    "Aunque todas las dependencias de datos son importantes de identificar al diseñar programas paralelos, las dependencias llevadas por bucle son particularmente importantes ya que los bucles son posiblemente el objetivo más común de los esfuerzos de paralelización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984761bc",
   "metadata": {},
   "source": [
    "#### Cómo Manejar las Dependencias de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff94a1",
   "metadata": {},
   "source": [
    "- En arquitecturas de memoria distribuida - comunicar los datos requeridos en puntos de sincronización.\n",
    "- En arquitecturas de memoria compartida - sincronizar las operaciones de lectura/escritura entre tareas.\n",
    "\n",
    "Manejar las dependencias de datos requiere una comprensión profunda de cómo el flujo de datos y el control afectan el paralelismo potencial. Las optimizaciones pueden incluir reestructurar algoritmos para minimizar las dependencias o implementar mecanismos para gestionarlas de forma efectiva, lo que puede incluir sincronización cuidadosa y uso estratégico de recursos de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8fee82",
   "metadata": {},
   "source": [
    "### Balanceo de Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79f848",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel49.PNG?raw=true\" width=\"750\" />\n",
    "</p>\n",
    "\n",
    "El balanceo de carga se refiere a la práctica de distribuir cantidades aproximadamente iguales de trabajo entre las tareas para que todas estén ocupadas todo el tiempo. Puede considerarse una minimización del tiempo de inactividad de las tareas.\n",
    "\n",
    "El balanceo de carga es importante para los programas paralelos por razones de rendimiento. Por ejemplo, si todas las tareas están sujetas a un punto de sincronización de barrera, la tarea más lenta determinará el rendimiento general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031512f",
   "metadata": {},
   "source": [
    "#### Cómo Lograr el Balance de Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b613b",
   "metadata": {},
   "source": [
    "**Particionar Equitativamente el Trabajo que Recibe Cada Tarea**\n",
    "- Para operaciones de arreglo/matriz donde cada tarea realiza un trabajo similar, distribuye de manera uniforme el conjunto de datos entre las tareas.\n",
    "- Para iteraciones de bucle donde el trabajo realizado en cada iteración es similar, distribuye las iteraciones de manera uniforme entre las tareas.\n",
    "- Si se utiliza una mezcla heterogénea de máquinas con características de rendimiento variables, asegúrate de usar alguna herramienta de análisis de rendimiento para detectar cualquier desequilibrio de carga y ajusta el trabajo en consecuencia.\n",
    "\n",
    "**Usar Asignación Dinámica de Trabajo**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel50.PNG?raw=true\" width=\"750\" />\n",
    "</p>\n",
    "\n",
    "Ciertas clases de problemas resultan en desequilibrios de carga incluso si los datos están distribuidos uniformemente entre las tareas:\n",
    "\n",
    "- Cuando la cantidad de trabajo que realizará cada tarea es intencionalmente variable, o no se puede predecir, puede ser útil utilizar un enfoque de grupo de tareas con programador. A medida que cada tarea termina su trabajo, recibe una nueva pieza de la cola de trabajo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel51.gif?raw=true\" width=\"400\" />\n",
    "</p>\n",
    "\n",
    "Finalmente, puede ser necesario diseñar un algoritmo que detecte y maneje desequilibrios de carga a medida que ocurren dinámicamente dentro del código. Esto puede significar ajustes en tiempo real durante la ejecución del programa para reasignar el trabajo de las tareas más ocupadas a las menos ocupadas, a fin de optimizar el uso de los recursos y mejorar el rendimiento general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982c446",
   "metadata": {},
   "source": [
    "### Granularidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c40ba",
   "metadata": {},
   "source": [
    "#### Razón de Cálculo / Comunicación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb83b1",
   "metadata": {},
   "source": [
    "En la computación paralela, la granularidad es una medida cualitativa de la relación entre el cálculo y la comunicación.\n",
    "Los períodos de cálculo están típicamente separados de los períodos de comunicación por eventos de sincronización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d7fa6",
   "metadata": {},
   "source": [
    "#### Paralelismo de Grano Fino (Fine-grain Parallelism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4b02e",
   "metadata": {},
   "source": [
    "- Se realizan cantidades relativamente pequeñas de trabajo computacional entre eventos de comunicación.\n",
    "- Baja relación de cálculo a comunicación.\n",
    "- Facilita el balanceo de carga.\n",
    "- Implica alta sobrecarga de comunicación y menos oportunidades para el aumento de rendimiento.\n",
    "- Si la granularidad es demasiado fina, es posible que la sobrecarga requerida para las comunicaciones y sincronización entre tareas tome más tiempo que el cálculo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel52.gif?raw=true\" width=\"200\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b4b08",
   "metadata": {},
   "source": [
    "#### Paralelismo de Grano Grueso (Coarse-grain Parallelism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c58cde",
   "metadata": {},
   "source": [
    "- Se realizan cantidades relativamente grandes de trabajo computacional entre eventos de comunicación/sincronización.\n",
    "- Alta relación de cálculo a comunicación.\n",
    "- Implica más oportunidades para el aumento de rendimiento.\n",
    "- Más difícil de balancear la carga de manera eficiente.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel53.gif?raw=true\" width=\"200\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286aebe",
   "metadata": {},
   "source": [
    "#### ¿Cuál es Mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646b041",
   "metadata": {},
   "source": [
    "La granularidad más eficiente depende del algoritmo y del entorno de hardware en el que se ejecuta.\n",
    "- En la mayoría de los casos, la sobrecarga asociada con las comunicaciones y la sincronización es alta en relación con la velocidad de ejecución, por lo que es ventajoso tener una granularidad gruesa.\n",
    "- El paralelismo de grano fino puede ayudar a reducir las sobrecargas debido al desequilibrio de carga.\n",
    "\n",
    "En la práctica, la elección entre granularidad fina y gruesa a menudo requiere un equilibrio entre la sobrecarga de gestión de las tareas paralelas y la eficiencia con la que se pueden realizar los cálculos. Los algoritmos y aplicaciones específicos pueden requerir sintonía fina y ajustes iterativos para encontrar el nivel de granularidad óptimo que maximice el rendimiento dado un conjunto particular de restricciones de cómputo y comunicación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23caf2",
   "metadata": {},
   "source": [
    "### I/O en Computación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92610393",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel54.gif?raw=true\" width=\"500\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435d885",
   "metadata": {},
   "source": [
    "#### Las Malas Noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7c9f2",
   "metadata": {},
   "source": [
    "**Jerarquía de Memoria y Operaciones de I/O**\n",
    "- Las operaciones de I/O (entrada/salida) son generalmente consideradas como inhibidores del paralelismo.\n",
    "- Las operaciones de I/O requieren órdenes de magnitud más tiempo que las operaciones de memoria.\n",
    "- Los sistemas de I/O paralelo pueden ser inmaduros o no estar disponibles para todas las plataformas.\n",
    "- En un entorno donde todas las tareas ven el mismo espacio de archivo, las operaciones de escritura pueden resultar en la sobreescritura de archivos.\n",
    "- Las operaciones de lectura pueden verse afectadas por la capacidad del servidor de archivos para manejar múltiples solicitudes de lectura al mismo tiempo.\n",
    "- I/O que debe realizarse a través de la red (NFS, no local) puede causar cuellos de botella severos e incluso colapsar servidores de archivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc0a68",
   "metadata": {},
   "source": [
    "#### Las Buenas Noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00317a1",
   "metadata": {},
   "source": [
    "**Sistemas de Archivos Paralelos**\n",
    "- Están disponibles sistemas de archivos paralelos. Por ejemplo:\n",
    "  - GPFS: General Parallel File System (IBM), ahora llamado IBM Spectrum Scale.\n",
    "  - Lustre: para clústeres de Linux (Intel)\n",
    "  - HDFS: Hadoop Distributed File System (Apache)\n",
    "  - PanFS: Panasas ActiveScale File System para clústeres de Linux (Panasas, Inc.)\n",
    "  - Y más - ver [Lista de sistemas de archivos paralelos distribuidos en Wikipedia](http://en.wikipedia.org/wiki/List_of_file_systems#Distributed_parallel_file_systems)\n",
    "\n",
    "La especificación de la interfaz de programación de I/O paralelo para MPI ha estado disponible desde 1996 como parte de MPI-2. Las implementaciones de proveedores y gratuitas ahora son comúnmente disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29be52",
   "metadata": {},
   "source": [
    "#### Algunas Sugerencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b2629",
   "metadata": {},
   "source": [
    "- **Regla #1:** Reducir el I/O total tanto como sea posible.\n",
    "- Si tienes acceso a un sistema de archivos paralelo, úsalo.\n",
    "- Escribir grandes bloques de datos en lugar de pequeños suele ser significativamente más eficiente.\n",
    "- Un menor número de archivos grandes rinde mejor que muchos archivos pequeños.\n",
    "- Confinar las operaciones de I/O a porciones seriales específicas del trabajo, y luego usar comunicaciones paralelas para distribuir datos a tareas paralelas. Por ejemplo, la Tarea 1 podría leer un archivo de entrada y luego comunicar los datos necesarios a otras tareas. Del mismo modo, la Tarea 1 podría realizar operaciones de escritura después de recibir los datos necesarios de todas las demás tareas.\n",
    "- Agregar operaciones de I/O entre tareas: en lugar de que muchas tareas realicen I/O, tener un subconjunto de tareas que lo hagan.\n",
    "\n",
    "En resumen, una estrategia eficaz de I/O en entornos de computación paralela puede tener un impacto significativo en el rendimiento general de una aplicación. Optimizar las operaciones de I/O para reducir la sobrecarga y evitar cuellos de botella es esencial para aprovechar al máximo los recursos de computación paralela."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be73f4e2",
   "metadata": {},
   "source": [
    "### Depuración (Debugging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9784b759",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3b457",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel55.gif?raw=true\" width=\"750\" />\n",
    "</p>\n",
    "\n",
    "La depuración de códigos paralelos puede ser increíblemente difícil, particularmente a medida que los códigos se escalan.\n",
    "\n",
    "La buena noticia es que hay excelentes depuradores disponibles para ayudar:\n",
    "- **Hilos (Threaded):** pthreads y OpenMP\n",
    "- **MPI**\n",
    "- **GPU / aceleradores**\n",
    "- **Híbrido**\n",
    "\n",
    "Los usuarios de Livermore Computing tienen acceso a varias herramientas de depuración paralela instaladas en los clústeres de LC:\n",
    "- **TotalView** de RogueWave Software\n",
    "- **DDT** de Allinea\n",
    "- **Inspector** de Intel\n",
    "- **Stack Trace Analysis Tool (STAT):** desarrollado localmente en LLNL\n",
    "\n",
    "Todas estas herramientas tienen una curva de aprendizaje asociada con ellas.\n",
    "\n",
    "Para detalles e información para comenzar, ver:\n",
    "- Páginas web de LC en [hpc.llnl.gov/software/development-environment-software](https://hpc.llnl.gov/software/development-environment-software)\n",
    "- Tutorial de TotalView: [hpc.llnl.gov/documentation/tutorials/totalview-tutorial](https://hpc.llnl.gov/documentation/tutorials/totalview-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57ff5a",
   "metadata": {},
   "source": [
    "#### Consejos para la Depuración de Códigos Paralelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360b770",
   "metadata": {},
   "source": [
    "1. **Comenzar Pequeño:** Comienza con una versión reducida del problema para simplificar la detección de errores.\n",
    "2. **Aumentar Gradualmente:** Aumenta el tamaño y la complejidad del código de forma gradual, depurando a cada paso.\n",
    "3. **Utilizar Asertos:** Usa asertos y cheques de coherencia de datos para validar el estado del programa en puntos críticos.\n",
    "4. **Comunicación y Sincronización:** Presta especial atención a la comunicación y sincronización entre tareas, ya que estos son puntos comunes donde pueden surgir problemas.\n",
    "5. **Utilizar Herramientas Especializadas:** Aprovecha las herramientas de depuración paralela, que pueden ofrecer capacidades de detección de patrones de bloqueo, carreras de datos y otros problemas de concurrencia.\n",
    "6. **Registros Verbosos:** Mantén registros detallados de las ejecuciones del programa para rastrear y reproducir errores.\n",
    "7. **Pruebas Unitarias y de Integración:** Implementa pruebas unitarias y de integración para verificar el funcionamiento correcto de componentes individuales y su integración.\n",
    "\n",
    "La depuración en el contexto de la computación paralela es a menudo más arte que ciencia, y requiere una combinación de herramientas adecuadas, técnicas sistemáticas y a veces, una buena dosis de paciencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64fd081",
   "metadata": {},
   "source": [
    "### Análisis de Rendimiento y Ajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f66b534",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel56.jpeg?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "Al igual que con la depuración, analizar y ajustar el rendimiento de programas paralelos puede ser mucho más desafiante que para programas seriales.\n",
    "\n",
    "Afortunadamente, existen varias herramientas excelentes para el análisis de rendimiento y el ajuste de programas paralelos.\n",
    "\n",
    "Los usuarios de Livermore Computing tienen acceso a varias de estas herramientas, la mayoría de las cuales están disponibles en todos los clústeres de producción.\n",
    "\n",
    "Algunos puntos de partida para herramientas instaladas en sistemas de LC:\n",
    "- Páginas web de LC: [hpc.llnl.gov/software/development-environment-software](https://hpc.llnl.gov/software/development-environment-software)\n",
    "- TAU (Tuning and Analysis Utilities): [Página de TAU](http://www.cs.uoregon.edu/research/tau/docs.php)\n",
    "- HPCToolkit: [Documentación de HPCToolkit](http://hpctoolkit.org/documentation.html)\n",
    "- Open|Speedshop: [Sitio de Open|Speedshop](https://www.openspeedshop.org/)\n",
    "- Vampir / Vampirtrace: [Sitio de Vampir](http://vampir.eu/)\n",
    "- Valgrind: [Sitio de Valgrind](http://valgrind.org/)\n",
    "- PAPI (Performance Application Programming Interface): [Sitio de PAPI](http://icl.cs.utk.edu/papi/)\n",
    "- mpiP: [Sitio de mpiP](http://mpip.sourceforge.net/)\n",
    "- memP: [Sitio de memP](http://memp.sourceforge.net/)\n",
    "\n",
    "***Consejos para el Análisis de Rendimiento y Ajuste:***\n",
    "\n",
    "1. **Identificar Cuellos de Botella:** Usa herramientas de perfilado para identificar dónde pasa la mayor parte del tiempo tu programa. Estos son a menudo los mejores candidatos para la optimización.\n",
    "\n",
    "2. **Evaluar la Paralelización:** Verifica que la carga de trabajo esté bien balanceada entre las tareas y que la sincronización y la comunicación no estén impactando negativamente el rendimiento.\n",
    "\n",
    "3. **Medir el Impacto de la Sincronización y la Comunicación:** Analiza cuánto tiempo se gasta en barreras de sincronización y en comunicación de datos entre procesos.\n",
    "\n",
    "4. **Optimizar el Uso de Memoria:** Asegúrate de que tu programa está utilizando la memoria de manera eficiente para evitar la contención y para que el acceso a la memoria no sea un cuello de botella.\n",
    "\n",
    "5. **Ajustar la Granularidad:** Si es necesario, ajusta la granularidad del paralelismo para mejorar el balance de carga y reducir la sobrecarga de comunicación.\n",
    "\n",
    "6. **Usar Contadores de Hardware:** Utiliza PAPI u otras interfaces para acceder a contadores de hardware y entender mejor el comportamiento de tu aplicación en relación con el hardware subyacente.\n",
    "\n",
    "7. **Revisar Algoritmos y Estructuras de Datos:** Considera la posibilidad de cambiar algoritmos y estructuras de datos por otros más eficientes o más adecuados para la computación paralela.\n",
    "\n",
    "8. **Iterar el Proceso:** El ajuste del rendimiento es un proceso iterativo. A menudo, una optimización llevará a la identificación de la siguiente área de mejora potencial.\n",
    "\n",
    "Analizar y ajustar el rendimiento es esencial para obtener el máximo provecho de los sistemas de cómputo paralelo. La integración de un análisis de rendimiento detallado y continuo en el ciclo de vida del desarrollo del software puede conducir a mejoras significativas en el rendimiento y la escalabilidad de los programas paralelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde33852",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "588.865px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
