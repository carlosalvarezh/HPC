{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Computación de Alto Desempeño</h1>\n",
    "<h1 align=\"center\">MPI - Glosario</h1>\n",
    "<h1 align=\"center\">2024</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "|[![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)](mailto:calvarezh@udemedellin.edu.co)||[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/HPC/blob/main/HPC15_MPIGlosario.ipynb)\n",
    "|-:|:-|--:|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Glosario de Directivas MPI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se ofrece un glosario detallado de las principales directivas de **MPI (Message Passing Interface)** presentadas en el capítulo anterior, junto con otras frecuentemente utilizadas en la programación paralela. El glosario está organizado por categorías para facilitar la comprensión y el uso de cada directiva según la tarea o actividad específica que se desea realizar.\n",
    "\n",
    "Las categorías incluyen:\n",
    "1. **Inicialización y Finalización del Entorno**: Directivas esenciales para configurar y limpiar el entorno de MPI.\n",
    "2. **Información del Comunicador y Procesos**: Funciones que permiten obtener detalles sobre los procesos y su organización.\n",
    "3. **Comunicación Punto a Punto**: Operaciones básicas de envío y recepción de mensajes entre dos procesos.\n",
    "4. **Comunicación Colectiva**: Directivas que permiten la coordinación y el intercambio de información entre todos los procesos.\n",
    "5. **Topologías Virtuales**: Herramientas para organizar los procesos en estructuras lógicas como mallas o grillas.\n",
    "6. **Tipos de Datos Derivados**: Funciones para definir y manipular estructuras complejas de datos.\n",
    "7. **Comunicación One-Sided (Una sola cara)**: Directivas que permiten la lectura y escritura en la memoria de otros procesos sin intervención directa.\n",
    "8. **Operaciones de Entrada/Salida Paralela (MPI I/O)**: Funciones para manejar archivos en sistemas de procesamiento paralelo.\n",
    "\n",
    "Cada categoría incluye ejemplos de uso y limitaciones, lo que facilita una mejor comprensión de cómo implementar estas directivas en proyectos paralelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Inicialización y Finalización del Entorno MPI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MPI_Init**\n",
    "- **Definición**: Inicializa el entorno MPI.\n",
    "- **Uso**: Configura el entorno de ejecución paralelo. Debe ser la primera llamada en un programa MPI.\n",
    "- **Sintaxis**: `MPI_Init(&argc, &argv);`\n",
    "- **Limitaciones**: Ninguna otra función MPI puede usarse antes de esta. Es obligatoria.\n",
    "\n",
    "#### **MPI_Finalize**\n",
    "- **Definición**: Finaliza el entorno MPI.\n",
    "- **Uso**: Limpia el entorno MPI y libera los recursos al terminar el programa.\n",
    "- **Sintaxis**: `MPI_Finalize();`\n",
    "- **Limitaciones**: Después de llamarse, no se pueden realizar más operaciones MPI.\n",
    "\n",
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    MPI_Init(&argc, &argv);  // Inicializa el entorno MPI\n",
    "    \n",
    "    // Cuerpo del programa MPI\n",
    "\n",
    "    MPI_Finalize();  // Finaliza el entorno MPI\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Información del Comunicador y Procesos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MPI_Comm_size**\n",
    "- **Definición**: Obtiene el número total de procesos dentro de un comunicador.\n",
    "- **Uso**: Determina cuántos procesos están participando en la ejecución paralela.\n",
    "- **Sintaxis**: `MPI_Comm_size(MPI_COMM_WORLD, &size);`\n",
    "- **Limitaciones**: Funciona solo después de `MPI_Init`.\n",
    "\n",
    "#### **MPI_Comm_rank**\n",
    "- **Definición**: Obtiene el identificador único (rank) del proceso actual dentro de un comunicador.\n",
    "- **Uso**: Identifica qué proceso está ejecutando el código en un conjunto de procesos.\n",
    "- **Sintaxis**: `MPI_Comm_rank(MPI_COMM_WORLD, &rank);`\n",
    "- **Limitaciones**: Solo puede usarse dentro de un comunicador y después de `MPI_Init`.\n",
    "\n",
    "#### **MPI_COMM_WORLD**\n",
    "- **Definición**: Comunicador predefinido que incluye a todos los procesos que participan en la ejecución.\n",
    "- **Uso**: Se utiliza para especificar el grupo de procesos en la mayoría de las funciones de MPI.\n",
    "- **Limitaciones**: No se puede modificar. Para dividir procesos en subgrupos, se deben crear nuevos comunicadores.\n",
    "\n",
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "int world_size, world_rank;\n",
    "MPI_Comm_size(MPI_COMM_WORLD, &world_size);  // Obtiene el número de procesos\n",
    "MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);  // Obtiene el identificador (rank) del proceso\n",
    "\n",
    "printf(\"Soy el proceso %d de un total de %d\\n\", world_rank, world_size);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Comunicación Punto a Punto**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MPI_Send**\n",
    "- **Definición**: Envía un mensaje desde un proceso a otro.\n",
    "- **Uso**: Utilizado para implementar la comunicación directa entre dos procesos.\n",
    "- **Sintaxis**: `MPI_Send(&data, count, MPI_INT, dest, tag, MPI_COMM_WORLD);`\n",
    "- **Limitaciones**: Bloquea el proceso hasta que el mensaje ha sido enviado por completo.\n",
    "\n",
    "#### **MPI_Recv**\n",
    "- **Definición**: Recibe un mensaje enviado desde otro proceso.\n",
    "- **Uso**: Permite la recepción de mensajes en una comunicación punto a punto.\n",
    "- **Sintaxis**: `MPI_Recv(&data, count, MPI_INT, source, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);`\n",
    "- **Limitaciones**: El proceso receptor queda bloqueado hasta recibir completamente el mensaje.\n",
    "\n",
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "if (world_rank == 0) {\n",
    "    int number = 42;\n",
    "    MPI_Send(&number, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);  // Proceso 0 envía un número al proceso 1\n",
    "} else if (world_rank == 1) {\n",
    "    int number;\n",
    "    MPI_Recv(&number, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);  // Proceso 1 recibe el número\n",
    "    printf(\"Proceso 1 recibió el número %d\\n\", number);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. **Comunicación Colectiva**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MPI_Bcast**\n",
    "- **Definición**: Difunde un mensaje desde un proceso a todos los demás en el comunicador.\n",
    "- **Uso**: Envía el mismo dato a todos los procesos, útil para sincronizar datos entre ellos.\n",
    "- **Sintaxis**: `MPI_Bcast(&data, count, MPI_INT, root, MPI_COMM_WORLD);`\n",
    "- **Limitaciones**: Todos los procesos deben llamar a la función simultáneamente.\n",
    "\n",
    "#### **MPI_Reduce**\n",
    "- **Definición**: Combina datos de todos los procesos mediante una operación (suma, multiplicación, etc.) y almacena el resultado en un proceso.\n",
    "- **Uso**: Se usa para reducir los datos de varios procesos a un solo resultado en el proceso raíz.\n",
    "- **Sintaxis**: `MPI_Reduce(&send_data, &recv_data, count, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);`\n",
    "- **Limitaciones**: Todos los procesos deben estar involucrados en la operación.\n",
    "\n",
    "#### **MPI_Scatter**\n",
    "- **Definición**: Distribuye diferentes partes de un conjunto de datos desde un proceso raíz a todos los demás procesos.\n",
    "- **Uso**: Divide un array o conjunto de datos y los distribuye entre los procesos.\n",
    "- **Sintaxis**: `MPI_Scatter(&sendbuf, sendcount, MPI_INT, &recvbuf, recvcount, MPI_INT, root, MPI_COMM_WORLD);`\n",
    "- **Limitaciones**: Todos los procesos deben recibir una porción del mismo tamaño.\n",
    "\n",
    "#### **MPI_Gather**\n",
    "- **Definición**: Recolecta datos de todos los procesos y los almacena en el proceso raíz.\n",
    "- **Uso**: Útil para reunir datos dispersos desde varios procesos y consolidarlos en un solo proceso.\n",
    "- **Sintaxis**: `MPI_Gather(&sendbuf, sendcount, MPI_INT, &recvbuf, recvcount, MPI_INT, root, MPI_COMM_WORLD);`\n",
    "- **Limitaciones**: El tamaño de los datos enviados debe ser el mismo para cada proceso.\n",
    "\n",
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "int data;\n",
    "if (world_rank == 0) {\n",
    "    data = 100;  // Solo el proceso 0 tiene inicialmente el valor\n",
    "}\n",
    "MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD);  // Difunde el valor a todos los procesos\n",
    "\n",
    "printf(\"Proceso %d recibió el valor %d\\n\", world_rank, data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **Topologías Virtuales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MPI_Cart_create**\n",
    "- **Definición**: Crea una topología cartesiana (malla o grilla) que organiza los procesos.\n",
    "- **Uso**: Facilita la comunicación entre procesos vecinos en aplicaciones que involucran simulaciones o problemas estructurados.\n",
    "- **Sintaxis**: `MPI_Cart_create(MPI_COMM_WORLD, ndims, dims, periods, reorder, &cart_comm);`\n",
    "- **Limitaciones**: Debe especificarse el tamaño y la periodicidad de la malla. Solo es útil en aplicaciones donde los procesos tienen vecindarios lógicos.\n",
    "\n",
    "#### **MPI_Cart_coords**\n",
    "- **Definición**: Obtiene las coordenadas de un proceso en una topología cartesiana.\n",
    "- **Uso**: Permite obtener la posición de un proceso dentro de la malla para realizar cálculos basados en su vecindario.\n",
    "- **Sintaxis**: `MPI_Cart_coords(cart_comm, rank, maxdims, coords);`\n",
    "- **Limitaciones**: Funciona solo si los procesos están organizados en una topología cartesiana.\n",
    "\n",
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "int dims[2] = {2, 2};  // Malla 2x2\n",
    "int periods[2] = {0, 0};  // Sin periodicidad\n",
    "MPI_Comm cart_comm;\n",
    "MPI_Cart_create(MPI_COMM_WORLD, 2, dims, periods, 0, &cart_comm);  // Crea una topología cartesiana\n",
    "\n",
    "int coords[2];\n",
    "MPI_Cart_coords(cart_comm, world_rank, 2, coords);  // Obtiene las coordenadas del proceso en la malla\n",
    "printf(\"Proceso %d tiene coordenadas (%d, %d)\\n\", world_rank, coords[0], coords[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. **Tipos de Datos Derivados** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MPI_Type_create_struct**\n",
    "- **Definición**: Crea un nuevo tipo de dato MPI basado en una estructura C o C++.\n",
    "- **Uso**: Permite definir y enviar estructuras complejas en lugar de enviar cada campo por separado.\n",
    "- **Sintaxis**: `MPI_Type_create_struct(count, block_lengths, displacements, types, &newtype);`\n",
    "- **Limitaciones**: Se debe tener en cuenta el alineamiento de la memoria. La configuración incorrecta de desplazamientos puede generar errores.\n",
    "\n",
    "#### **MPI_Type_commit**\n",
    "- **Definición**: Compromete un nuevo tipo de dato derivado, haciéndolo disponible para la comunicación.\n",
    "- **Uso**: Finaliza el proceso de definición de un tipo derivado para que pueda ser utilizado en comunicaciones.\n",
    "- **Sintaxis**: `MPI_Type_commit(&newtype);`\n",
    "- **Limitaciones**: Después de ser comprometido, no puede ser modificado. El tipo debe liberarse cuando ya no sea necesario.\n",
    "\n",
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "typedef struct {\n",
    "    int id;\n",
    "    float value;\n",
    "} data_t;\n",
    "\n",
    "data_t my_data = { world_rank, 3.14 * world_rank };\n",
    "\n",
    "MPI_Datatype new_type;\n",
    "int lengths[2] = {1, 1};\n",
    "MPI_Aint displacements[2];\n",
    "MPI_Datatype types[2] = {MPI_INT, MPI_FLOAT};\n",
    "\n",
    "displacements[0] = offsetof(data_t, id);\n",
    "displacements[1] = offsetof(data_t, value);\n",
    "\n",
    "MPI_Type_create_struct(2, lengths, displacements, types, &new_type);\n",
    "MPI_Type_commit(&new_type);\n",
    "\n",
    "if (world_rank == 0) {\n",
    "    MPI_Send(&my_data, 1, new_type, 1, 0, MPI_COMM_WORLD);  // Envia la estructura\n",
    "} else if (world_rank == 1) {\n",
    "    MPI_Recv(&my_data, 1, new_type, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "    printf(\"Proceso 1 recibió id = %d, value = %f\\n\", my_data.id, my_data.value);\n",
    "}\n",
    "MPI_Type_free(&new_type);  // Libera el tipo derivado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. **Comunicación One-Sided (Una sola cara)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MPI_Put**\n",
    "- **Definición**: Coloca datos en la memoria de otro proceso sin que este participe activamente en la comunicación.\n",
    "- **Uso**: Facilita la escritura directa en la memoria de otros procesos, optimizando ciertos patrones de comunicación.\n",
    "- **Sintaxis**: `MPI_Put(&data, count, MPI_INT, target_rank, target_disp, target_count, MPI_INT, win);`\n",
    "- **Limitaciones**: Requiere la creación de ventanas de memoria y la correcta sincronización para evitar condiciones de carrera.\n",
    "\n",
    "#### **MPI_Win_create**\n",
    "- **Definición**: Crea una ventana de memoria compartida que puede ser accedida por otros procesos.\n",
    "- **Uso**: Permite la implementación de la comunicación \"one-sided\", donde un proceso accede a la memoria de otro.\n",
    "- **Sintaxis**: `MPI_Win_create(base, size, disp_unit, MPI_INFO_NULL, MPI_COMM_WORLD, &win);`\n",
    "- **Limitaciones**: Debe ser liberada correctamente cuando ya no se necesita (`MPI_Win_free`).\n",
    "\n",
    "#### **MPI_Win_lock / MPI_Win_unlock**\n",
    "- **Definición**: Bloquea o desbloquea una ventana de memoria, asegurando acceso exclusivo durante la comunicación.\n",
    "- **Uso**: Se utiliza para proteger la memoria compartida, permitiendo que un solo proceso acceda a ella en un momento dado.\n",
    "- **Sintaxis**:\n",
    "  - `MPI_Win_lock(MPI_LOCK_EXCLUSIVE, target_rank, 0, win);`\n",
    "  - `MPI_Win_unlock(target_rank, win);`\n",
    "- **Limitaciones**: Un uso incorrecto puede causar condiciones de carrera o bloqueos en la comunicación.\n",
    "\n",
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "int data = 42;\n",
    "MPI_Win win;\n",
    "\n",
    "MPI_Win_create(&data, sizeof(int), sizeof(int), MPI_INFO_NULL, MPI_COMM_WORLD, &win);\n",
    "\n",
    "if (world_rank == 0) {\n",
    "    int value = 100;\n",
    "    MPI_Win_lock(MPI_LOCK_EXCLUSIVE, 1, 0, win);  // Bloquea la ventana en el proceso 1\n",
    "    MPI_Put(&value, 1, MPI_INT, 1, 0, 1, MPI_INT, win);  // Escribe en la memoria del proceso 1\n",
    "    MPI_Win_unlock(1, win);  // Desbloquea la ventana\n",
    "    printf(\"Proceso 0 envió %d al proceso 1\\n\", value);\n",
    "}\n",
    "\n",
    "MPI_Win_free(&win);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. **Operaciones de Entrada/Salida Paralela (MPI I/O)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **MPI_File_open**\n",
    "- **Definición**: Abre un archivo en modo lectura, escritura o ambos en un entorno paralelo.\n",
    "- **Uso**: Permite que varios procesos accedan a un archivo simultáneamente, lo que es ideal en aplicaciones donde múltiples procesos necesitan escribir o leer datos compartidos.\n",
    "- **Sintaxis**: `MPI_File_open(MPI_COMM_WORLD, \"filename\", MPI_MODE_CREATE | MPI_MODE_WRONLY, MPI_INFO_NULL, &fh);`\n",
    "- **Limitaciones**: Es necesario asegurarse de que cada proceso tenga el espacio adecuado en el archivo y evitar que los procesos sobrescriban accidentalmente los datos de otros, lo que requiere una gestión adecuada de los desplazamientos.\n",
    "\n",
    "#### **MPI_File_write_at**\n",
    "- **Definición**: Escribe datos en un archivo en una posición específica determinada por el desplazamiento dentro del archivo.\n",
    "- **Uso**: Permite que cada proceso escriba en su propia sección del archivo sin interferir con las otras secciones, mejorando la eficiencia de la escritura en entornos paralelos.\n",
    "- **Sintaxis**: `MPI_File_write_at(fh, offset, buffer, count, MPI_INT, &status);`\n",
    "- **Limitaciones**: Los procesos deben calcular cuidadosamente sus desplazamientos (offsets) para evitar que sus escrituras se solapen con las de otros procesos.\n",
    "\n",
    "#### **MPI_File_read_at**\n",
    "- **Definición**: Lee datos desde un archivo en una posición específica determinada por el desplazamiento.\n",
    "- **Uso**: Permite que cada proceso lea datos desde su propia parte del archivo, sin interferir con las lecturas de otros procesos.\n",
    "- **Sintaxis**: `MPI_File_read_at(fh, offset, buffer, count, MPI_INT, &status);`\n",
    "- **Limitaciones**: Al igual que con la escritura, los desplazamientos deben gestionarse cuidadosamente para asegurar que cada proceso lea desde la posición correcta del archivo.\n",
    "\n",
    "#### **MPI_File_close**\n",
    "- **Definición**: Cierra un archivo abierto en un entorno paralelo.\n",
    "- **Uso**: Después de que todos los procesos hayan terminado de leer o escribir, es necesario cerrar el archivo para liberar los recursos.\n",
    "- **Sintaxis**: `MPI_File_close(&fh);`\n",
    "- **Limitaciones**: No se debe continuar realizando operaciones en un archivo después de cerrarlo. Todos los procesos deben cerrar sus archivos al finalizar las operaciones de entrada/salida.\n",
    "\n",
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "c"
    }
   },
   "outputs": [],
   "source": [
    "MPI_File fh;\n",
    "MPI_Status status;\n",
    "\n",
    "MPI_File_open(MPI_COMM_WORLD, \"output.txt\", MPI_MODE_CREATE | MPI_MODE_WRONLY, MPI_INFO_NULL, &fh);\n",
    "\n",
    "char data[20];\n",
    "sprintf(data, \"Proceso %d\\n\", world_rank);\n",
    "\n",
    "MPI_File_write_at(fh, world_rank * 20, data, 20, MPI_CHAR, &status);  // Cada proceso escribe en su parte\n",
    "\n",
    "MPI_File_close(&fh);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Directivas case-sensitive**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las **directivas de MPI son case-sensitive** (sensibles a mayúsculas y minúsculas). En MPI, todas las directivas y constantes se escriben en **mayúsculas** como una convención del lenguaje, lo que facilita su identificación. Este estilo ayuda a diferenciar claramente las funciones y constantes de MPI de otras funciones o variables definidas por el programador.\n",
    "\n",
    "### ¿Por qué se utilizan mayúsculas?\n",
    "1. **Convención de estilo**: En muchas bibliotecas y estándares de programación en C, como MPI, las directivas y constantes se escriben en mayúsculas para distinguirlas de otros elementos del código. Esto mejora la legibilidad y estructura del programa.\n",
    "   \n",
    "2. **Consistencia y uniformidad**: Mantener las directivas de MPI en mayúsculas asegura un estilo consistente y claro. Cualquier función perteneciente a MPI es fácilmente reconocible, ya que sigue esta convención.\n",
    "\n",
    "### Ejemplos de directivas en mayúsculas:\n",
    "- **MPI_Init**\n",
    "- **MPI_Finalize**\n",
    "- **MPI_COMM_WORLD**\n",
    "- **MPI_Send**\n",
    "- **MPI_Recv**\n",
    "- **MPI_File_open**\n",
    "\n",
    "### Importancia del case-sensitive en MPI:\n",
    "Dado que las directivas de MPI son case-sensitive, escribir `mpi_init` en lugar de `MPI_Init` provocará un error, ya que el compilador lo interpretará como un identificador distinto. En C, las minúsculas y mayúsculas no son intercambiables, por lo que es **fundamental** respetar esta convención para asegurar que el código se ejecute correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
