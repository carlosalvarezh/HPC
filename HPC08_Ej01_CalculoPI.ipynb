{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09d2c62-3f7e-470c-8658-2e0fd4217b5e",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Computación de Alto Desempeño</h1>\n",
    "<h1 align=\"center\">OpenMP</h1>\n",
    "<h1 align=\"center\">Ejemplo 01: Cálculo de pi por integración numérica</h1>\n",
    "<h1 align=\"center\">2024</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fe4852-9456-4738-be4d-a6c98579e1f7",
   "metadata": {},
   "source": [
    "***\n",
    "|[![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)](mailto:calvarezh@udemedellin.edu.co)||[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/HPC/blob/main/HPC08_Ej01_CalculoPI.ipynb)\n",
    "|-:|:-|--:|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b69395f-e2a4-4c73-a65c-a78535999394",
   "metadata": {},
   "source": [
    "## Cálculo de $\\pi$ mediante integración numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad751be-69c7-4a37-8537-7a87a0d99c37",
   "metadata": {},
   "source": [
    "Calcular el valor de $\\pi$ mediante integración numérica, utilizando la fórmula:\n",
    "\n",
    "$$\n",
    "\\pi = \\int_0^1 \\frac{4}{1 + x^2} \\, dx\n",
    "$$\n",
    "\n",
    "Para aproximar la integral, utilizamos la **suma de rectángulos**:\n",
    "\n",
    "$$\n",
    "\\sum_{i=0}^{N-1} F(x_i) \\cdot \\Delta x \\approx \\pi\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $x_i$ es el punto en el intervalo en el que se evalúa la función.\n",
    "- $F(x_i) = \\frac{4}{1 + x_i^2}$ es el valor de la función en el punto $x_i$.\n",
    "- $\\Delta x = \\frac{1}{N}$ es el ancho de cada rectángulo, donde $N$ es el número de rectángulos que usamos para aproximar la integral.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c2b1cc-3fa6-4bf4-b5fd-22987c987f8a",
   "metadata": {},
   "source": [
    "### Código Serial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb5177-0b26-4056-a375-67601a7d8772",
   "metadata": {},
   "source": [
    "Primero, implementaremos el cálculo de $\\pi$ utilizando un enfoque secuencial en C.\n",
    "\n",
    "```c\n",
    "#include <stdio.h>\n",
    "\n",
    "int main() {\n",
    "    long long N = 1000000;  // Número de intervalos (mayor N, más precisión)\n",
    "    double pi = 0.0;\n",
    "    double delta_x = 1.0 / (double)N;  // Ancho de cada rectángulo\n",
    "\n",
    "    // Bucle para sumar las áreas de los rectángulos\n",
    "    for (long long i = 0; i < N; i++) {\n",
    "        double x_i = (i + 0.5) * delta_x;  // Punto medio del intervalo\n",
    "        pi += 4.0 / (1.0 + x_i * x_i);     // Añadir altura del rectángulo a la suma\n",
    "    }\n",
    "\n",
    "    pi *= delta_x;  // Multiplicar por el ancho del rectángulo para obtener el área total\n",
    "\n",
    "    printf(\"Valor aproximado de pi: %.15f\\n\", pi);\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "**Explicación del Código Serial:**\n",
    "\n",
    "1. **Inicialización de Variables:**\n",
    "   - `N`: Número de intervalos o rectángulos para la integración.\n",
    "   - `pi`: Variable que almacenará el valor aproximado de $\\pi$.\n",
    "   - `delta_x`: Ancho de cada rectángulo, dado por $\\Delta x = \\frac{1}{N}$.\n",
    "\n",
    "2. **Ciclo de Suma:**\n",
    "   - En el ciclo `for`, se suman las alturas de los rectángulos en cada punto medio $x_i$, que se calcula como $x_i = (i + 0.5) \\cdot \\Delta x$.\n",
    "   - La función que determina la altura de cada rectángulo es $F(x_i) = \\frac{4}{1 + x_i^2}$, que se suma a la variable `pi`.\n",
    "\n",
    "3. **Multiplicación Final:**\n",
    "   - Al final, multiplicamos el valor de `pi` acumulado por $\\Delta x$ para obtener el área total bajo la curva, que es la aproximación de $\\pi$.\n",
    "\n",
    "**Salida Esperada del Código Serial:**\n",
    "\n",
    "```\n",
    "Valor aproximado de pi: 3.141592653589793\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512440c-e6e1-4a0b-9456-2b945d50b4e0",
   "metadata": {},
   "source": [
    "### Paralelización del Código con OpenMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b748bf7f-26ac-4745-b66a-d8bc3c39a0e9",
   "metadata": {},
   "source": [
    "Ahora que tenemos la versión secuencial, procedemos a analizar cómo podemos paralelizar el cálculo con OpenMP. Para ello, identificamos las partes del código que pueden ejecutarse en paralelo.\r\n",
    "\r\n",
    "**Análisis para la Paralelización:**\r\n",
    "\r\n",
    "1. **Identificación de la Parte Paralelizante:**\r\n",
    "   - El bucle `for` es independiente para cada iteración, lo que significa que no hay dependencia entre las iteraciones. Cada iteración solo calcula un valor para un rectángulo específico y lo añade a la suma de `pi`.\r\n",
    "\r\n",
    "2. **Riesgo de Condiciones de Carrera:**\r\n",
    "   - Si varios hilos intentan actualizar la misma variable `pi` al mismo tiempo, pueden ocurrir **condiciones de carrera**. Para evitarlo, utilizaremos la cláusula `reduction` de OpenMP para asegurar que cada hilo trabaje en su propia copia de la variable `pi` y combine los resultados al final.\r\n",
    "\r\n",
    "**Código Paralelo con OpenMP:**\r\n",
    "\r\n",
    "```c\r\n",
    "#include <omp.h>\r\n",
    "#include <stdio.h>\r\n",
    "\r\n",
    "int main() {\r\n",
    "    long long N = 1000000;  // Número de intervalos (mayor N, más precisión)\r\n",
    "    double pi = 0.0;\r\n",
    "    double delta_x = 1.0 / (double)N;  // Ancho de cada rectángulo\r\n",
    "\r\n",
    "    // Paralelizar la suma utilizando OpenMP\r\n",
    "    #pragma omp parallel\r\n",
    "    {\r\n",
    "        double sum_local = 0.0;  // Variable local para cada hilo\r\n",
    "        #pragma omp for\r\n",
    "        for (long long i = 0; i < N; i++) {\r\n",
    "            double x_i = (i + 0.5) * delta_x;  // Punto medio del intervalo\r\n",
    "            sum_local += 4.0 / (1.0 + x_i * x_i);\r\n",
    "        }\r\n",
    "\r\n",
    "        // Combinar resultados parciales en la variable global pi\r\n",
    "        #pragma omp atomic\r\n",
    "        pi += sum_local * delta_x;\r\n",
    "    }\r\n",
    "\r\n",
    "    printf(\"Valor aproximado de pi: %.15f\\n\", pi);\r\n",
    "    return 0;\r\n",
    "}\r\n",
    "```\r\n",
    "\r\n",
    "**Explicación de la Versión Paralela:**\r\n",
    "\r\n",
    "1. **Región Paralela:**\r\n",
    "   - Usamos `#pragma omp parallel` para iniciar una región paralela donde cada hilo calcula una parte de la suma total.\r\n",
    "\r\n",
    "2. **Variable Local `sum_local`:**\r\n",
    "   - Cada hilo tiene su propia copia de `sum_local` para evitar condiciones de carrera. Cada hilo suma sus valores en `sum_local` en el bucle paralelo.\r\n",
    "\r\n",
    "3. **Combinar Resultados:**\r\n",
    "   - Una vez que cada hilo ha calculado su parte, utilizamos `#pragma omp atomic` para asegurar que la actualización de la variable global `pi` se realice de forma segura (es decir, sin interferencia entre los hilos).\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e2338-e565-4226-be58-074d5ccce0b8",
   "metadata": {},
   "source": [
    "### Métricas Clave para Evaluar el Desempeño:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c59023-ac8d-4025-9c81-a74fdca4d62d",
   "metadata": {},
   "source": [
    "Para determinar el **desempeño** de las implementaciones secuencial y paralela del cálculo de $\\pi$, puedes usar varias **métricas de rendimiento** que ayudarán a comparar cuál de las dos es más eficiente. Aunque ambas implementaciones deberían dar el mismo resultado final, el enfoque de paralelización está diseñado para reducir el tiempo de ejecución, especialmente en sistemas con múltiples núcleos.\r\n",
    "\r\n",
    "1. **Tiempo de Ejecución** (Execution Time):\r\n",
    "   - **Descripción**: Es el tiempo total que tarda cada implementación (secundaria y paralela) en completar el cálculo de $\\pi$.\r\n",
    "   - **Cómo medirlo**: Puedes usar temporizadores como `omp_get_wtime()` en OpenMP o funciones de la biblioteca estándar como `clock()` o `chrono` en C++.\r\n",
    "   - **Comparación**: El tiempo de ejecución de la versión paralela debería ser menor que el de la versión secuencial si la paralelización está bien implementada y el sistema tiene suficientes recursos (como núcleos).\r\n",
    "\r\n",
    "   **Ejemplo en C usando `omp_get_wtime()`**:\r\n",
    "   ```c\r\n",
    "   double start_time = omp_get_wtime();\r\n",
    "   // Código a medir\r\n",
    "   double end_time = omp_get_wtime();\r\n",
    "   printf(\"Tiempo de ejecución: %f segundos\\n\", end_time - start_time);\r\n",
    "   ```\r\n",
    "\r\n",
    "2. **Aceleración** (Speedup):\r\n",
    "   - **Descripción**: Es una métrica que mide cuánto más rápido es el código paralelo en comparación con el código secuencial. Se calcula como la razón entre el tiempo de ejecución del código secuencial y el tiempo de ejecución del código paralelo.\r\n",
    "   - **Fórmula**: \r\n",
    "     $$\r\n",
    "     \\text{Speedup} = \\frac{T_{\\text{sec}}}{T_{\\text{par}}}\r\n",
    "     $$\r\n",
    "     donde $T_{\\text{sec}}$ es el tiempo de ejecución del código secuencial y $T_{\\text{par}}$ es el tiempo de ejecución del código paralelo.\r\n",
    "   - **Interpretación**: Un valor de **Speedup** mayor que 1 indica que la paralelización mejoró el rendimiento. Si el **Speedup** es 1, significa que la paralelización no tuvo ningún efecto, y si es menor que 1, indica que la paralelización empeoró el rendimiento (algo no está bien implementado).\r\n",
    "\r\n",
    "3. **Eficiencia** (Efficiency):\r\n",
    "   - **Descripción**: Es la proporción de la aceleración obtenida en comparación con el número de hilos utilizados. Evalúa si los recursos paralelos (como núcleos) se están utilizando de manera efectiva.\r\n",
    "   - **Fórmula**: \r\n",
    "     $$\r\n",
    "     \\text{Eficiencia} = \\frac{\\text{Speedup}}{P}\r\n",
    "     $$\r\n",
    "     donde $P$ es el número de hilos o procesadores utilizados.\r\n",
    "   - **Interpretación**: Una eficiencia cercana a 1 indica un buen uso de los recursos paralelos. A medida que aumentas el número de hilos, la eficiencia tiende a disminuir debido a la sobrecarga de coordinación entre hilos.\r\n",
    "\r\n",
    "4. **Uso de CPU** (CPU Utilization):\r\n",
    "   - **Descripción**: Mide el porcentaje de tiempo que el procesador está ocupado durante la ejecución del programa. En la versión paralela, deberías observar un uso elevado de la CPU cuando todos los núcleos están trabajando.\r\n",
    "   - **Cómo medirlo**: En sistemas UNIX/Linux, herramientas como `top` o `htop` pueden mostrar el uso de la CPU. En Windows, puedes usar el \"Administrador de tareas\".\r\n",
    "\r\n",
    "5. **Escalabilidad**:\r\n",
    "   - **Descripción**: Evalúa cómo cambia el rendimiento al variar el número de hilos o procesadores. Una buena implementación paralela debería escalar bien, es decir, debería mejorar el rendimiento al aumentar el número de hilos.\r\n",
    "   - **Cómo medirla**: Ejecuta la versión paralela con diferentes números de hilos (por ejemplo, 1, 2, 4, 8, 16) y obseva cómo varía el tiempo de ejecución.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ec851-5df8-4df3-9353-169c9f6ba3db",
   "metadata": {},
   "source": [
    "Para medir el **tiempo de ejecución**, tanto en la versión secuencial como en la paralela, puedes usar `omp_get_wtime()` en OpenMP. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb989a-960a-43df-9173-006668db6f4a",
   "metadata": {},
   "source": [
    "### **Versión Secuencial:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c8039-e79b-4a17-a880-04cd344a9608",
   "metadata": {},
   "source": [
    "```c\r\n",
    "#include <stdio.h>\r\n",
    "#include <omp.h>\r\n",
    "\r\n",
    "int main() {\r\n",
    "    long long N = 1000000;\r\n",
    "    double pi = 0.0;\r\n",
    "    double delta_x = 1.0 / (double)N;\r\n",
    "\r\n",
    "    // Iniciar el temporizador\r\n",
    "    double start_time = omp_get_wtime();\r\n",
    "\r\n",
    "    for (long long i = 0; i < N; i++) {\r\n",
    "        double x_i = (i + 0.5) * delta_x;\r\n",
    "        pi += 4.0 / (1.0 + x_i * x_i);\r\n",
    "    }\r\n",
    "\r\n",
    "    pi *= delta_x;\r\n",
    "\r\n",
    "    // Detener el temporizador\r\n",
    "    double end_time = omp_get_wtime();\r\n",
    "\r\n",
    "    printf(\"Valor aproximado de pi: %.15f\\n\", pi);\r\n",
    "    printf(\"Tiempo de ejecución (secuencial): %f segundos\\n\", end_time - start_time;\r\n",
    "\r\n",
    "    return 0;\r\n",
    "}\r\n",
    "```\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c284d48-ab92-434b-a141-fa621dd80853",
   "metadata": {},
   "source": [
    "### **Versión Paralela:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60cbf69-1c43-4192-8b44-1046c4ea6847",
   "metadata": {},
   "source": [
    "```c\r\n",
    "#include <omp.h>\r\n",
    "#include <stdio.h>\r\n",
    "\r\n",
    "int main() {\r\n",
    "    long long N = 1000000;\r\n",
    "    double pi = 0.0;\r\n",
    "    double delta_x = 1.0 / (double)N;\r\n",
    "\r\n",
    "    // Iniciar el temporizador\r\n",
    "    double start_time = omp_get_wtime();\r\n",
    "\r\n",
    "    #pragma omp parallel\r\n",
    "    {\r\n",
    "        double sum_local = 0.0;\r\n",
    "        #pragma omp for\r\n",
    "        for (long long i = 0; i < N; i++) {\r\n",
    "            double x_i = (i + 0.5) * delta_x;\r\n",
    "            sum_local += 4.0 / (1.0 + x_i * x_i);\r\n",
    "        }\r\n",
    "\r\n",
    "        #pragma omp atomic\r\n",
    "        pi += sum_local * delta_x;\r\n",
    "    }\r\n",
    "\r\n",
    "    // Detener el temporizador\r\n",
    "    double end_time = omp_get_wtime();\r\n",
    "\r\n",
    "    printf(\"Valor aproximado de pi: %.15f\\n\", pi);\r\n",
    "    printf(\"Tiempo de ejecución (paralelo): %f segundos\\n\", end_time - start_time);\r\n",
    "\r\n",
    "    return 0;\r\n",
    "}\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c8ab4-a7f4-4de7-9f0b-e3fc505d34f8",
   "metadata": {},
   "source": [
    "### **Ejemplo de Análisis de Desempeño:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d587862-5ab1-4dfd-ad7b-4e491e97e1bb",
   "metadata": {},
   "source": [
    "1. Ejecuta ambos códigos (secuencial y paralelo).\r\n",
    "2. Mide el **tiempo de ejecución** de cada uno.\r\n",
    "3. Calcula el **speedup**:\r\n",
    "   $$\r\n",
    "   \\text{Speedup} = \\frac{T_{\\text{sec}}}{T_{\\text{par}}}\r\n",
    "   $$\r\n",
    "   Si, por ejemplo, el tiempo de ejecución secuencial es de 2.0 segundos y el tiempo paralelo es de 0.5 segundos con 4 hilos, el **speedup** sería:\r\n",
    "   $$\r\n",
    "   \\text{Speedup} = \\frac{2.0}{0.5} = 4.0\r\n",
    "   $$\r\n",
    "4. Calcula la **eficiencia**:\r\n",
    "   $$\r\n",
    "   \\text{Eficiencia} = \\frac{\\text{Speedup}}{P}\r\n",
    "   $$\r\n",
    "   Si usamos 4 hilos, la eficiencia sería:\r\n",
    "   $$\r\n",
    "   \\text{Eficiencia} = \\frac{4.0}{4} = 1.0\r\n",
    "   $$\r\n",
    "   Esto indicaría una eficiencia perfecta (100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d55fc9-fc13-49e9-bf55-85e482e99345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
