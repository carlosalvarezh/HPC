{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98196e40-fc9a-46ad-8cf7-07fa5b272d7a",
   "metadata": {
    "id": "98196e40-fc9a-46ad-8cf7-07fa5b272d7a"
   },
   "source": [
    "<h1 align=\"center\">Computación de Alto Desempeño</h1>\n",
    "<h1 align=\"center\">OpenMP</h1>\n",
    "<h1 align=\"center\">2024</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8606e1-8ac9-4f6d-bc49-4455c0a44ce2",
   "metadata": {
    "id": "ed8606e1-8ac9-4f6d-bc49-4455c0a44ce2"
   },
   "source": [
    "***\n",
    "|[![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)](mailto:calvarezh@udemedellin.edu.co)||[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/HPC/blob/main/HPC07_OpenMP.ipynb)\n",
    "|-:|:-|--:|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HNWYvYl68ENp",
   "metadata": {
    "id": "HNWYvYl68ENp"
   },
   "source": [
    "## Introducción a OpenMP y MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Rwz6DbWW8M5Q",
   "metadata": {
    "id": "Rwz6DbWW8M5Q"
   },
   "source": [
    "En el ámbito de la computación de alto rendimiento (HPC), OpenMP y MPI son dos tecnologías ampliamente utilizadas para paralelizar aplicaciones, permitiendo que los programas aprovechen el poder de múltiples procesadores o núcleos. Cada una de estas herramientas tiene sus propias características, ventajas y limitaciones, y se emplean en diferentes contextos dependiendo de las necesidades del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kEFhWhld8Qes",
   "metadata": {
    "id": "kEFhWhld8Qes"
   },
   "source": [
    "### **OpenMP (Open Multi-Processing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q_eMWN468FvA",
   "metadata": {
    "id": "q_eMWN468FvA"
   },
   "source": [
    "**Características Principales:**\n",
    "- **Enfoque en Memoria Compartida:** OpenMP es ideal para sistemas con memoria compartida, donde todos los hilos de ejecución tienen acceso a la misma memoria física. Esto incluye arquitecturas como computadoras multicore o multiprocesadores con un solo espacio de memoria.\n",
    "- **Facilidad de Uso:** OpenMP se integra directamente en lenguajes como C, C++ y Fortran mediante directivas de compilador, lo que permite paralelizar el código de manera incremental y sencilla.\n",
    "- **Modelo de Programación Basado en Hilos:** OpenMP utiliza hilos (threads) para ejecutar tareas en paralelo. El programador puede controlar el número de hilos y cómo se distribuyen las tareas entre ellos.\n",
    "- **Paralelismo Explícito:** El programador indica explícitamente qué partes del código deben ejecutarse en paralelo, lo que da un control fino sobre la optimización.\n",
    "\n",
    "**Cuándo Usar OpenMP:**\n",
    "- En sistemas con arquitecturas de memoria compartida.\n",
    "- Cuando se requiere un paralelismo de grano fino, donde las tareas pueden ser fácilmente divididas en pequeños fragmentos.\n",
    "- En proyectos donde se busca una implementación rápida y sencilla de paralelismo sin necesidad de grandes cambios en la estructura del código.\n",
    "\n",
    "**Ventajas:**\n",
    "- Sencillez y rapidez en la implementación.\n",
    "- Facilita la depuración debido a su integración directa con el código secuencial.\n",
    "- Permite paralelismo dinámico, ajustando el número de hilos en tiempo de ejecución.\n",
    "\n",
    "**Limitaciones:**\n",
    "- No es adecuado para sistemas de memoria distribuida.\n",
    "- La escalabilidad está limitada al número de núcleos disponibles en una sola máquina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46A9LHBu8YVK",
   "metadata": {
    "id": "46A9LHBu8YVK"
   },
   "source": [
    "### **MPI (Message Passing Interface)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VQiM3ZFz8ZF2",
   "metadata": {
    "id": "VQiM3ZFz8ZF2"
   },
   "source": [
    "**Características Principales:**\n",
    "- **Enfoque en Memoria Distribuida:** MPI es ideal para sistemas de memoria distribuida, donde cada nodo del sistema tiene su propia memoria local, como en clústeres de computadoras.\n",
    "- **Flexibilidad y Escalabilidad:** MPI permite que las aplicaciones se escalen a miles de nodos, lo que es esencial en aplicaciones científicas y de ingeniería que requieren un poder de cómputo masivo.\n",
    "- **Modelo de Programación Basado en Mensajes:** MPI utiliza un modelo de paso de mensajes, donde los procesos se comunican entre sí enviando y recibiendo mensajes. Cada proceso tiene su propio espacio de memoria, lo que reduce los problemas de sincronización.\n",
    "- **Compatibilidad y Portabilidad:** MPI es compatible con múltiples plataformas y es el estándar de facto en computación paralela en sistemas de memoria distribuida.\n",
    "\n",
    "**Cuándo Usar MPI:**\n",
    "- En sistemas con arquitecturas de memoria distribuida, como clústeres de computadoras.\n",
    "- En aplicaciones que requieren alta escalabilidad y que necesitan ejecutarse en varios nodos de una red.\n",
    "- Cuando se trabaja con datos que no pueden ser almacenados en la memoria de una sola máquina y deben distribuirse entre varios nodos.\n",
    "\n",
    "**Ventajas:**\n",
    "- Alta escalabilidad y flexibilidad.\n",
    "- Permite aprovechar sistemas heterogéneos, donde cada nodo puede tener diferentes capacidades de hardware.\n",
    "- Reduce los problemas de sincronización gracias a su modelo de memoria distribuida.\n",
    "\n",
    "**Limitaciones:**\n",
    "- Mayor complejidad en la programación y depuración.\n",
    "- Requiere un diseño cuidadoso del algoritmo para minimizar el overhead de comunicación entre nodos.\n",
    "- No es tan eficiente en arquitecturas de memoria compartida debido al overhead de comunicación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A5PYh6E8-vfH",
   "metadata": {
    "id": "A5PYh6E8-vfH"
   },
   "source": [
    "## OpenMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VUVVyEN3ABDe",
   "metadata": {
    "id": "VUVVyEN3ABDe"
   },
   "source": [
    "### OpenMP es:\n",
    "\n",
    "- **Una Interfaz de Programación de Aplicaciones (API):** Que se utiliza para dirigir explícitamente el paralelismo en memoria compartida utilizando múltiples hilos.\n",
    "- **Compuesta por tres componentes principales:**\n",
    "  - **Directivas del compilador**\n",
    "  - **Rutinas de la biblioteca en tiempo de ejecución**\n",
    "  - **Variables de entorno**\n",
    "- **Una abreviatura para:**\n",
    "  - **Versión corta:** Open Multi-Processing\n",
    "  - **Versión larga:** Especificaciones abiertas para la Multi-Processing mediante el trabajo colaborativo entre partes interesadas de la industria del hardware y software, el gobierno y la academia.\n",
    "\n",
    "### OpenMP no es:\n",
    "\n",
    "- **Implementada necesariamente de manera idéntica por todos los proveedores.**\n",
    "- **Garantizada para hacer el uso más eficiente de la memoria compartida.**\n",
    "- **Obligada a verificar dependencias de datos, conflictos de datos, condiciones de carrera o interbloqueos.**\n",
    "- **Obligada a verificar secuencias de código que causen que un programa se clasifique como no conforme.**\n",
    "- **Diseñada para garantizar que la entrada o salida al mismo archivo sea síncrona cuando se ejecuta en paralelo. El programador es responsable de sincronizar la entrada y salida.**\n",
    "\n",
    "### Objetivos de OpenMP:\n",
    "\n",
    "- **Estandarización:**\n",
    "  - Proporcionar un estándar entre una variedad de arquitecturas/plataformas de memoria compartida.\n",
    "  - Definido y respaldado conjuntamente por un grupo de grandes proveedores de hardware y software.\n",
    "\n",
    "- **Eficiencia y Sencillez:**\n",
    "  - Establecer un conjunto simple y limitado de directivas para programar máquinas de memoria compartida.\n",
    "  - Se puede implementar un paralelismo significativo utilizando solo 3 o 4 directivas.\n",
    "  - Este objetivo se está volviendo menos relevante con cada nueva versión.\n",
    "\n",
    "- **Facilidad de Uso:**\n",
    "  - Proporcionar la capacidad de paralelizar un programa secuencial de manera incremental, a diferencia de las bibliotecas de paso de mensajes que típicamente requieren un enfoque de todo o nada.\n",
    "  - Proporcionar la capacidad de implementar paralelismo tanto de grano grueso como de grano fino.\n",
    "\n",
    "- **Portabilidad:**\n",
    "  - La API está especificada para C/C++ y Fortran.\n",
    "  - Foro público para la API y membresía.\n",
    "  - La mayoría de las principales plataformas han sido implementadas, incluidas plataformas Unix/Linux y Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RFfr4jtPBw4i",
   "metadata": {
    "id": "RFfr4jtPBw4i"
   },
   "source": [
    "## Modelo de Programación OpenMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-tFOwNBXBw7S",
   "metadata": {
    "id": "-tFOwNBXBw7S"
   },
   "source": [
    "OpenMP se basa en dos modelos principales: el modelo de memoria y el modelo de ejecución.\n",
    "\n",
    "#### **Modelo de Memoria Compartida:**\n",
    "OpenMP está diseñado para máquinas multiprocesador/multinúcleo con memoria compartida. La arquitectura subyacente puede ser de memoria compartida de acceso uniforme (UMA) o de acceso no uniforme (NUMA).\n",
    "\n",
    "#### **Modelo de Ejecución de OpenMP:**\n",
    "\n",
    "**Paralelismo Basado en Hilos:**\n",
    "Los programas de OpenMP logran el paralelismo exclusivamente mediante el uso de hilos. Un hilo de ejecución es la unidad más pequeña de procesamiento que puede ser programada por un sistema operativo. Puedes pensar en un hilo como una subrutina que se puede ejecutar de manera autónoma.\n",
    "\n",
    "- Los hilos existen dentro de los recursos de un solo proceso. Sin el proceso, los hilos dejan de existir.\n",
    "- Típicamente, el número de hilos coincide con el número de procesadores/núcleos de la máquina. Sin embargo, el uso real de los hilos depende de la aplicación.\n",
    "\n",
    "**Paralelismo Explícito:**\n",
    "OpenMP es un modelo de programación explícito (no automático), lo que ofrece al programador un control total sobre la paralelización.\n",
    "\n",
    "- La paralelización puede ser tan simple como tomar un programa secuencial e insertar directivas de compilador.\n",
    "- O tan complejo como insertar subrutinas para establecer múltiples niveles de paralelismo, bloqueos y hasta bloqueos anidados.\n",
    "\n",
    "**Modelo Fork-Join:**\n",
    "OpenMP utiliza el modelo de ejecución paralelo fork-join.\n",
    "\n",
    "- **FORK:** Todos los programas OpenMP comienzan como un solo proceso: el hilo maestro. El hilo maestro ejecuta secuencialmente hasta que se encuentra la primera construcción de región paralela.\n",
    "- **JOIN:** Cuando los hilos del equipo completan las instrucciones en la construcción de la región paralela, se sincronizan y terminan, dejando solo al hilo maestro.\n",
    "\n",
    "El número de regiones paralelas y los hilos que las componen son arbitrarios.\n",
    "\n",
    "**Basado en Directivas de Compilador:**\n",
    "La mayor parte del paralelismo en OpenMP se especifica mediante el uso de directivas de compilador que se incrustan en el código fuente de C/C++ o Fortran.\n",
    "\n",
    "**Paralelismo Anidado:**\n",
    "La API permite colocar regiones paralelas dentro de otras regiones paralelas. Las implementaciones pueden o no admitir esta característica.\n",
    "\n",
    "**Hilos Dinámicos:**\n",
    "La API permite que el entorno de ejecución altere dinámicamente el número de hilos utilizados para ejecutar regiones paralelas, con la intención de promover un uso más eficiente de los recursos, si es posible. Las implementaciones pueden o no soportar esta característica.\n",
    "\n",
    "**Entrada/Salida (I/O):**\n",
    "OpenMP no especifica nada sobre I/O paralelo. Depende completamente del programador garantizar que la entrada y salida se realicen correctamente en el contexto de un programa multi-hilo.\n",
    "\n",
    "#### **Interacción entre el Modelo de Ejecución y el Modelo de Memoria:**\n",
    "\n",
    "- **Single-Program-Multiple-Data (SPMD):** Es el paradigma de programación subyacente: todos los hilos tienen el potencial de ejecutar el mismo código de programa; sin embargo, cada hilo puede acceder y modificar diferentes datos y recorrer diferentes caminos de ejecución.\n",
    "  \n",
    "- **Vista de Memoria Relajada:** OpenMP proporciona una vista \"relajada\" y \"temporal\" de la memoria de los hilos: los hilos tienen acceso igual a la memoria compartida donde las variables pueden ser recuperadas/almacenadas. Cada hilo también tiene sus propias copias temporales de variables que pueden modificarse independientemente de las variables en la memoria.\n",
    "\n",
    "- **Consistencia de Datos:** Cuando es crítico que todos los hilos tengan una vista consistente de una variable compartida, el programador (o el compilador) es responsable de asegurar que la variable sea actualizada por todos los hilos según sea necesario, mediante una acción explícita, como `FLUSH`, o implícitamente (a través del reconocimiento del compilador al salir de regiones paralelas).\n",
    "\n",
    "#### **Programación en OpenMP:**\n",
    "\n",
    "- Método para iniciar hilos paralelos.\n",
    "- Método para descubrir cuántos hilos están ejecutándose.\n",
    "- Necesidad de identificar hilos de manera única.\n",
    "- Método para unir hilos para ejecución secuencial.\n",
    "- Método para sincronizar hilos.\n",
    "- Asegurar una vista consistente de los elementos de datos cuando sea necesario.\n",
    "- Requiere verificar dependencias de datos, conflictos de datos, condiciones de carrera o interbloqueos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3VQHpAmLC0ts",
   "metadata": {
    "id": "3VQHpAmLC0ts"
   },
   "source": [
    "## Descripción General de la API OpenMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc2cc99-8976-4c41-88f3-39b7466b8ec7",
   "metadata": {
    "id": "NPvEhyKhDLyZ"
   },
   "source": [
    "### Tres Componentes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd2e207-4503-4618-a166-2e6959ba2371",
   "metadata": {},
   "source": [
    "La API de OpenMP se compone de tres componentes distintos. A partir de la versión 4.0:\n",
    "\n",
    "1. **Directivas del Compilador (44)**\n",
    "2. **Rutinas de Biblioteca en Tiempo de Ejecución (35)**\n",
    "3. **Variables de Entorno (13)**\n",
    "\n",
    "El desarrollador de la aplicación decide cómo emplear estos componentes. En el caso más simple, solo se necesitan algunos de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7febb-e382-48b9-947c-be86135d44c7",
   "metadata": {},
   "source": [
    "### **Directivas del Compilador:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028fb25-7eeb-4b4c-9733-1757a2163ff2",
   "metadata": {},
   "source": [
    "Las directivas del compilador aparecen como comentarios en tu código fuente y son ignoradas por los compiladores a menos que se indique lo contrario, generalmente especificando la bandera de compilador adecuada.\n",
    "\n",
    "Las directivas del compilador de OpenMP se utilizan para varios propósitos:\n",
    "- Crear una región paralela.\n",
    "- Dividir bloques de código entre hilos.\n",
    "- Distribuir las iteraciones de los bucles entre hilos.\n",
    "- Serializar secciones de código.\n",
    "- Sincronizar el trabajo entre hilos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa16c50-7ce3-439d-9133-ead63232869b",
   "metadata": {},
   "source": [
    "### Sintaxis básica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c843259-ad62-4561-83e0-044956fbe9e1",
   "metadata": {},
   "source": [
    "La sintaxis básica de una directiva en OpenMP es la siguiente:\n",
    "\n",
    "```c\n",
    "sentinel       directive-name      [clause, ...]\n",
    "```\n",
    "**Ejemplo en C/C++:**\n",
    "\n",
    "```c\n",
    "#pragma omp directive-name [clause, ...]\n",
    "```\n",
    "\n",
    "```c\n",
    "#pragma omp parallel default(shared) private(beta, pi)\n",
    "```\n",
    "\n",
    "- **sentinel**: Es el indicador que marca que lo que sigue es una directiva de OpenMP. En C y C++, el sentinel es `#pragma omp`, mientras que en Fortran se utilizan `!$omp`, `C$omp`, o `*$omp`.\n",
    "  \n",
    "- **directive-name**: Es el nombre de la directiva que especifica qué operación o región de código debe ser paralelizada. Algunas de las directivas más comunes en OpenMP son:\n",
    "  - `parallel`: Define una región paralela donde el código será ejecutado por múltiples hilos.\n",
    "  - `for` o `do`: Se usa para paralelizar bucles `for` en C/C++ o `do` en Fortran.\n",
    "  - `sections`: Define diferentes bloques de código que se ejecutan en paralelo de manera independiente.\n",
    "  - `single`: Indica que una sola hebra (thread) debe ejecutar una región específica del código.\n",
    "  - `master`: Especifica que sólo el hilo maestro debe ejecutar esa sección del código.\n",
    "  - `critical`: Define una sección del código que debe ser ejecutada por un único hilo a la vez, garantizando acceso exclusivo a recursos compartidos.\n",
    "\n",
    "- **clause**: Son modificadores opcionales que se pueden añadir a las directivas para ajustar el comportamiento de la paralelización. Ejemplos de cláusulas incluyen:\n",
    "  - `private(var)`: Indica que la variable `var` es privada para cada hilo.\n",
    "  - `shared(var)`: Especifica que `var` es una variable compartida entre todos los hilos.\n",
    "  - `reduction(op:var)`: Realiza una reducción con la operación `op` (como `+`, `*`) sobre la variable `var` al final de la región paralela.\n",
    "  - `num_threads(N)`: Especifica que la región paralela debe usar `N` hilos.\n",
    "  - `schedule(type[,chunk])`: Controla cómo se distribuyen las iteraciones del bucle entre los hilos (`static`, `dynamic`, `guided`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f44ae7-e0f0-4a14-a31b-b021849d72dd",
   "metadata": {},
   "source": [
    "### **Rutinas de Biblioteca en Tiempo de Ejecución:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c7713a-48fc-406d-9850-e51874b4cdde",
   "metadata": {},
   "source": [
    "La API de OpenMP incluye un número cada vez mayor de rutinas de biblioteca en tiempo de ejecución. Estas rutinas se utilizan para diversos propósitos, como:\n",
    "\n",
    "- Establecer y consultar el número de hilos.\n",
    "- Consultar el identificador único de un hilo (ID del hilo) y el tamaño del equipo de hilos.\n",
    "- Establecer y consultar la función de hilos dinámicos.\n",
    "- Consultar si se está en una región paralela y a qué nivel.\n",
    "- Establecer y consultar el paralelismo anidado.\n",
    "- Establecer, inicializar y terminar bloqueos y bloqueos anidados.\n",
    "- Consultar el tiempo de reloj y la resolución.\n",
    "\n",
    "**Ejemplo en C/C++:**\n",
    "```c\n",
    "#include <omp.h>\n",
    "int omp_get_num_threads(void)\n",
    "```\n",
    "\n",
    "Ten en cuenta que para C/C++, generalmente debes incluir el archivo de encabezado `<omp.h>`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f53334-7c56-43d4-ae98-82aa3b3de66d",
   "metadata": {},
   "source": [
    "#### **Variables de Entorno:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc716c-0fc0-4fb7-a33e-313c80592744",
   "metadata": {},
   "source": [
    "OpenMP proporciona varias variables de entorno para controlar la ejecución del código paralelo en tiempo de ejecución. Estas variables pueden utilizarse para controlar aspectos como:\n",
    "\n",
    "- Establecer el número de hilos.\n",
    "- Especificar cómo se dividen las iteraciones de los bucles.\n",
    "- Asignar hilos a procesadores.\n",
    "- Habilitar/deshabilitar el paralelismo anidado y establecer los niveles máximos de paralelismo anidado.\n",
    "- Habilitar/deshabilitar los hilos dinámicos.\n",
    "- Establecer el tamaño de la pila de hilos.\n",
    "- Establecer la política de espera de hilos.\n",
    "\n",
    "**Ejemplo de cómo establecer variables de entorno en `bash`:**\n",
    "```bash\n",
    "export OMP_NUM_THREADS=8\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9fcb2-8dcf-4a4f-8fd5-dab3fc512005",
   "metadata": {},
   "source": [
    "### **Estructura General del Código OpenMP en C/C++:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WwUxT4esC0vt",
   "metadata": {
    "id": "WwUxT4esC0vt"
   },
   "source": [
    "```c\n",
    "#include <omp.h>\n",
    "\n",
    "main ()  {\n",
    "\n",
    "    int var1, var2, var3;\n",
    "\n",
    "    // Código secuencial\n",
    "    //      .\n",
    "    //      .\n",
    "    //      .\n",
    "\n",
    "    // Inicio de la sección paralela. Se crea un equipo de hilos.\n",
    "    // Especificar el alcance de las variables.\n",
    "\n",
    "    #pragma omp parallel private(var1, var2) shared(var3)\n",
    "    {\n",
    "        // Sección paralela ejecutada por todos los hilos.\n",
    "        //      .\n",
    "        // Otras directivas de OpenMP.\n",
    "        //      .\n",
    "        // Llamadas a la biblioteca en tiempo de ejecución.\n",
    "        //      .\n",
    "        // Todos los hilos se unen al hilo maestro y terminan.\n",
    "    }  \n",
    "\n",
    "    // Retomar el código secuencial\n",
    "    //      .\n",
    "    //      .\n",
    "\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d4648-0f3b-448a-9a37-d010c2f66ed1",
   "metadata": {},
   "source": [
    "### Ejemplos de Directivas OpenMP:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2361ea98-8d81-4ac2-bd89-0d00b8acf316",
   "metadata": {},
   "source": [
    "1. **Ejemplo con la directiva `parallel`:**\n",
    "   ```c\n",
    "   #pragma omp parallel num_threads(4)\n",
    "   {\n",
    "       printf(\"Esto se ejecuta en paralelo\\n\");\n",
    "   }\n",
    "   ```\n",
    "   En este ejemplo, la directiva `#pragma omp parallel` crea un equipo de 4 hilos (`num_threads(4)`) que ejecutarán el bloque de código dentro de las llaves en paralelo.\n",
    "\n",
    "2. **Ejemplo con la directiva `for`:**\n",
    "   ```c\n",
    "   #pragma omp parallel for\n",
    "   for (int i = 0; i < 10; i++) {\n",
    "       printf(\"Iteración %d ejecutada por el hilo %d\\n\", i, omp_get_thread_num());\n",
    "   }\n",
    "   ```\n",
    "   Aquí, el bucle `for` se paraleliza, y cada iteración del bucle es ejecutada por diferentes hilos en paralelo. La función `omp_get_thread_num()` devuelve el número del hilo que está ejecutando una iteración.\n",
    "\n",
    "3. **Ejemplo con la cláusula `reduction`:**\n",
    "   ```c\n",
    "   int sum = 0;\n",
    "   #pragma omp parallel for reduction(+:sum)\n",
    "   for (int i = 0; i < 100; i++) {\n",
    "       sum += i;\n",
    "   }\n",
    "   ```\n",
    "   En este caso, se usa la cláusula `reduction(+:sum)` para garantizar que la operación de suma se realice correctamente en paralelo. Cada hilo suma sus propios resultados y al final combina esos resultados de manera segura en la variable `sum`.\n",
    "\n",
    "4. **Ejemplo con la cláusula `critical`:**\n",
    "   Asegura que una sección crítica del código sea ejecutada por un solo hilo a la vez. Esto es importante cuando se actualizan variables compartidas para evitar condiciones de carrera.\n",
    "\n",
    "   ```c\n",
    "   #pragma omp critical\n",
    "   {\n",
    "       // Sólo un hilo puede ejecutar esta sección a la vez.\n",
    "   }\n",
    "   ```\n",
    "\n",
    "5. **Ejemplo con la cláusula `single`:**\n",
    "   Indica que la sección de código debe ser ejecutada por un solo hilo (no necesariamente el hilo maestro), mientras que los demás hilos esperan.\n",
    "\n",
    "   ```c\n",
    "   #pragma omp single\n",
    "   {\n",
    "       // Sólo un hilo ejecuta este sección a la vez.\n",
    "   }\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19432c2-e05a-4f8b-bbc9-c398c1b53c0f",
   "metadata": {},
   "source": [
    "### Ejemplo práctico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca9252-4ff0-4960-bac6-aeda0803289e",
   "metadata": {},
   "source": [
    "```c\n",
    "// OpenMP header\r\n",
    "#include <omp.h>\r\n",
    "#include <stdio.h>\r\n",
    "#include <stdlib.h>\r\n",
    "\r\n",
    "int main(int argc, char* argv[])\r\n",
    "{\r\n",
    "\tint nthreads, tid;\r\n",
    "\r\n",
    "\t// Begin of parallel region\r\n",
    "\t#pragma omp parallel private(nthreads, tid)\r\n",
    "\t{\r\n",
    "\t\t// Getting thread number\r\n",
    "\t\ttid = omp_get_thread_num();\r\n",
    "\t\tprintf(\"Hello world from thread = %d\\n\",\r\n",
    "\t\t\ttid);\r\n",
    "\r\n",
    "\t\tif (tid == 0) {\r\n",
    "\r\n",
    "\t\t\t// Only master thread does this\r\n",
    "\t\t\tnthreads = omp_get_num_threads();\r\n",
    "\t\t\tprintf(\"Number of threads = %d\\n\",\r\n",
    "\t\t```\t\tnthreads);\r\n",
    "\t\t}\r\n",
    "\t}\r\n",
    "}\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69541f4-d72e-4d06-a772-7c48d37a5a15",
   "metadata": {},
   "source": [
    "#### Explicación del código paralelo en C con OpenMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70026eb-5320-4b8b-a3e4-ee1194c4e387",
   "metadata": {},
   "source": [
    "A continuación se explica de manera detallada cada línea del código en C que utiliza OpenMP para ejecutar código en paralelo.\r\n",
    "\r\n",
    "```c\r\n",
    "// OpenMP header\r\n",
    "#include <omp.h>\r\n",
    "#include <stdio.h>\r\n",
    "#include <stdlib.h>\r\n",
    "```\r\n",
    "\r\n",
    "***Línea 1:***\r\n",
    "```c\r\n",
    "#include <omp.h>\r\n",
    "```\r\n",
    "- **Descripción**: Este encabezado (`omp.h`) es necesario para utilizar las funciones y directivas de OpenMP. Proporciona todas las definiciones de las funciones de la biblioteca OpenMP, como `omp_get_thread_num()` y `omp_get_num_threads()`, que permiten controlar la ejecución paralela y obtener información sobre los hilos.\r\n",
    "\r\n",
    "***Línea 2-3:***\r\n",
    "```c\r\n",
    "#include <stdio.h>\r\n",
    "#include <stdlib.h>\r\n",
    "```\r\n",
    "- **Descripción**: Estas son las bibliotecas estándar de C. `stdio.h` permite el uso de funciones de entrada y salida como `printf()`, mientras que `stdlib.h` proporciona funciones estándar como `malloc()`, `exit()`, etc. Aunque no se usan funciones de `stdlib.h` en este código en particular, es común incluirlo como estándar.\r\n",
    "\r\n",
    "***Línea 4-5:***\r\n",
    "```c\r\n",
    "int main(int argc, char* argv[])\r\n",
    "{\r\n",
    "    int nthreads, tid;\r\n",
    "```\r\n",
    "- **Descripción**: \r\n",
    "  - **`int main(int argc, char* argv[])`**: Esta es la función principal del programa en C. `argc` y `argv[]` permiten que el programa reciba argumentos desde la línea de comandos, aunque en este caso no se utilizan.\r\n",
    "  - **`int nthreads, tid;`**: Aquí se declaran dos variables enteras:\r\n",
    "    - `nthreads`: Esta variable almacenará el número total de hilos que se están utilizando en la región paralela.\r\n",
    "    - `tid`: Almacena el número de identificación (ID) de cada hilo (thread), que será diferente para cada hilo creado.\r\n",
    "\r\n",
    "***Línea 6:***\r\n",
    "```c\r\n",
    "    #pragma omp parallel private(nthreads, tid)\r\n",
    "```\r\n",
    "- **Descripción**: Esta línea indica el inicio de una **región paralela** con OpenMP. La directiva `#pragma omp parallel` crea múltiples hilos que ejecutarán el bloque de código contenido dentro de las llaves `{}`.\r\n",
    "  - **`private(nthreads, tid)`**: Esto significa que cada hilo tendrá su propia copia de las variables `nthreads` y `tid`. Así, cada hilo tendrá una versión independiente de estas variables y no compartirá sus valores con otros hilos, lo que evita condiciones de carrera en estas variables.\r\n",
    "\r\n",
    "***Línea 7-8:***\r\n",
    "```c\r\n",
    "    {\r\n",
    "        tid = omp_get_thread_num();\r\n",
    "```\r\n",
    "- **Descripción**: \r\n",
    "  - **`omp_get_thread_num()`**: Esta función devuelve el número de identificación (ID) del hilo que está ejecutando el bloque de código. Cada hilo tiene un ID único, comenzando desde 0 (el hilo maestro) hasta `N-1` (donde `N` es el número de hilos).\r\n",
    "  - La variable `tid` (ID del hilo) se inicializa para cada hilo individualmente con el valor que devuelve `omp_get_thread_num()`.\r\n",
    "\r\n",
    "***Línea 9:***\r\n",
    "```c\r\n",
    "        printf(\"Hello world from thread = %d\\n\", tid);\r\n",
    "```\r\n",
    "- **Descripción**: Esta línea imprime un mensaje que indica qué hilo está ejecutando la línea de código. Utiliza el valor de `tid` para identificar el número de hilo y lo imprime con la función `printf()`.\r\n",
    "\r\n",
    "  Ejemplo de salida para cuatro hilos:\r\n",
    "  ```\r\n",
    "  Hello world from thread = 0\r\n",
    "  Hello world from thread = 1\r\n",
    "  Hello world from thread = 2\r\n",
    "  Hello world from thread = 3\r\n",
    "  ```\r\n",
    "\r\n",
    "***Línea 10-11:***\r\n",
    "```c\r\n",
    "        if (tid == 0) {\r\n",
    "```\r\n",
    "- **Descripción**: Este `if` verifica si el hilo que está ejecutando la condición es el **hilo maestro**. En OpenMP, el hilo maestro siempre tiene `tid = 0`. Este bloque se ejecuta solo para el hilo con ID 0, que es el encargado de realizar tareas específicas que no deben ser paralelizadas.\r\n",
    "\r\n",
    "***Línea 12-13:***\r\n",
    "```c\r\n",
    "            nthreads = omp_get_num_threads();\r\n",
    "```\r\n",
    "- **Descripción**: \r\n",
    "  - **`omp_get_num_threads()`**: Esta función devuelve el número total de hilos que se están utilizando en la región paralela. En este caso, la función se llama solo desde el hilo maestro (con `tid = 0`).\r\n",
    "  - Luego, el valor de `nthreads` se almacena en la variable `nthreads` para que el hilo maestro sepa cuántos hilos en total están en ejecución.\r\n",
    "\r\n",
    "***Línea 14-15:***\r\n",
    "```c\r\n",
    "            printf(\"Number of threads = %d\\n\", nthreads);\r\n",
    "        }\r\n",
    "```\r\n",
    "- **Descripción**: Esta línea imprime el número total de hilos que se están utilizando. Solo el hilo maestro (con `tid = 0`) ejecuta esta línea, por lo que solo se imprimirá una vez.\r\n",
    "\r\n",
    "  Ejemplo de salida:\r\n",
    "  ```\r\n",
    "  Number of threads = 4\r\n",
    "  ```\r\n",
    "\r\n",
    "***Línea 16:***\r\n",
    "```c\r\n",
    "    }\r\n",
    "}\r\n",
    "```\r\n",
    "- **Descripción**: \r\n",
    "  - Esta línea cierra la región paralela, ya que el bloque de código dentro de las llaves `{}` ha terminado.\r\n",
    "  - Todos los hilos que se crearon para ejecutar la región paralela finalizarán y se volverá al hilo maestro para continuar con el flujo del programa. Después de la región paralela, solo el hilo maestro continuará ejecutando el resto del código (si hubiera más código después).\r\n",
    "\r\n",
    "***Resumiendo:***\r\n",
    "\r\n",
    "- El código ejecuta una **región paralela** donde se crean múltiples hilos, cada uno de los cuales imprime su número de identificación (ID).\r\n",
    "- Solo el hilo maestro (`tid = 0`) obtiene y muestra el número total de hilos utilizados en la región paralela.\r\n",
    "- Cada hilo tiene su propia versión de las variables `nthreads` y `tid` gracias a la cláusula `private`, lo que garantiza que no haya interferencia entre los hilos en esas variables.\r\n",
    "\r\n",
    "Este código ilustra un ejemplo simple de paralelización con OpenMP, donde varias partes del código se ejecutan en paralelo, y el hilo maestro realiza una tarea específica (mostrar el número de hilos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61be29-da28-4f30-a650-57cd87578e15",
   "metadata": {},
   "source": [
    "### Compilación y ejecución de un programa OpenMP en C y en Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed5ec67-edd1-4ad9-b781-729fd0a8dac8",
   "metadata": {},
   "source": [
    "Para compilar y ejecutar el programa `omphello.c` anterior:\n",
    "\n",
    "```bash\n",
    "gcc -o omphello omphello.c -fopenmp\n",
    "export OMP_NUM_THREADS=4\n",
    "./omphello\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867d9dd5-eccd-44c7-8f46-9ba4d3f6233c",
   "metadata": {},
   "source": [
    "### **Funciones y Variables de Entorno Útiles en OpenMP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6709be-1249-4a5e-95fb-c7e9bb1df4d2",
   "metadata": {},
   "source": [
    "Algunas funciones útiles a usar en relación con OpenMP incluyen:\n",
    "\n",
    "- `omp_get_num_threads()`: Devuelve el número de hilos paralelos.\n",
    "- `omp_get_thread_num()`: Devuelve el ID único del hilo actual.\n",
    "- `omp_set_num_threads(n)`: Establece el número de hilos a utilizar en las regiones paralelas en `n`.\n",
    "\n",
    "No es necesario establecer explícitamente el número de hilos en el código. El mismo efecto se puede lograr configurando la variable de entorno `OMP_NUM_THREADS`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a9557-9f01-4637-9964-eae87e8dd27f",
   "metadata": {},
   "source": [
    "## Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb2fb31-2eaa-4db0-a0a3-151994c3503b",
   "metadata": {},
   "source": [
    "***Ejercicio 1: Introducción a Regiones Paralelas -*** Escribe un programa en C que cree una región paralela utilizando 4 hilos. Cada hilo debe imprimir su número de identificación (ID) y un mensaje de \"Hola desde el hilo X\". Usa la función `omp_get_thread_num()` para obtener el ID del hilo.\r\n",
    "\r\n",
    "**Indicaciones**:\r\n",
    "- Usa la directiva `#pragma omp parallel` para crear la región paralela.\r\n",
    "- Limita el número de hilos a 4 utilizando `omp_set_num_threads()` o la variable de entorno `OMP_NUM_THREADS`.\r\n",
    "\r\n",
    "**Resultado esperado**:\r\n",
    "Cada hilo debe imprimir un mensaje indicando su número de hilo y la frase \"Hola desde el hilo X\", donde X es el número del hilo.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "***Ejercicio 2: Control de Número de Hilos -*** Escribe un programa que determine el número máximo de hilos disponibles en tu sistema utilizando `omp_get_num_procs()`. Luego, ajusta el número de hilos a la mitad de ese valor y crea una región paralela donde cada hilo imprima su número de identificación y el número total de hilos en ejecución.\r\n",
    "\r\n",
    "**Indicaciones**:\r\n",
    "- Usa `omp_get_num_procs()` para determinar el número de procesadores disponibles.\r\n",
    "- Ajusta el número de hilos a la mitad del número de procesadores disponibles usando `omp_set_num_threads()`.\r\n",
    "- Dentro de la región paralela, imprime el ID del hilo y el número total de hilos utilizando `omp_get_thread_num()` y `omp_get_num_threads()`.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "***Ejercicio 3: Paralelización de un Bucle `for` -*** Escribe un programa que calcule la suma de los números enteros del 1 al 100 utilizando un bucle `for` paralelo con OpenMP. Cada hilo debe calcular la suma de una parte del rango y al final combinar los resultados utilizando la cláusula `reduction`.\r\n",
    "\r\n",
    "**Indicaciones**:\r\n",
    "- Utiliza `#pragma omp parallel for reduction(+:sum)` para paralelizar el bucle y realizar la suma en paralelo.\r\n",
    "- Al final del programa, imprime la suma total de los números del 1 al 100.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "***Ejercicio 4: Secciones Paralelas -*** Escribe un programa que cree dos secciones paralelas. En la primera sección, se debe imprimir la tabla de multiplicar del 2, y en la segunda sección, la tabla de multiplicar del 3. Cada sección debe ser ejecutada por un hilo diferente.\r\n",
    "\r\n",
    "**Indicaciones**:\r\n",
    "- Usa la directiva `#pragma omp sections` para definir las dos secciones.\r\n",
    "- Asegúrate de que cada tabla de multiplicar sea calculada y mostrada por un hilo distinto.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "***Ejercicio 5: Control de Variables Privadas y Compartidas -*** Escribe un programa que inicialice una variable `total` en 0. Luego, dentro de una región paralela con 4 hilos, cada hilo debe sumar un número diferente (por ejemplo, 1, 2, 3 o 4) a la variable `total`. Utiliza las cláusulas `private` y `shared` para manejar correctamente las variables.\r\n",
    "\r\n",
    "**Indicaciones**:\r\n",
    "- Declara `total` como una variable compartida usando `shared`.\r\n",
    "- Asegúrate de que la variable que almacena los números individuales que suma cada hilo sea privada usando `private`.\r\n",
    "- Al final, imprime el valor total calculado por todos los hilos.\r\n",
    "\r\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
